{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11630187,"sourceType":"datasetVersion","datasetId":7296865},{"sourceId":11630272,"sourceType":"datasetVersion","datasetId":7296924}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n!pip install -q tokenizers datasets\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import BPE, WordLevel\nfrom transformers import MBartTokenizerFast\nfrom tokenizers.trainers import BpeTrainer, WordLevelTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\n!pip install -q transformers datasets tokenizers huggingface_hub\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import WordLevel\nfrom tokenizers.trainers import WordLevelTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\nfrom transformers import PreTrainedTokenizerFast\nimport re\n\nfrom transformers import (\n    EncoderDecoderModel, BertConfig, BertModel, PreTrainedTokenizerFast,\n    MBartForConditionalGeneration, TrainingArguments, Trainer, AutoModel\n)\nfrom datasets import Dataset\nimport torch\nimport os\n\nfrom transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n!pip install evaluate\nimport evaluate\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:13:06.995557Z","iopub.execute_input":"2025-05-05T19:13:06.996214Z","iopub.status.idle":"2025-05-05T19:13:43.699950Z","shell.execute_reply.started":"2025-05-05T19:13:06.996190Z","shell.execute_reply":"2025-05-05T19:13:43.699075Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2025-05-05 19:13:27.300072: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746472407.484629      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746472407.540057      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.16)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n/kaggle/input/ugce-phone-to-hindi/phone_20k_en2hi_translation.csv\n/kaggle/input/phone-data-text/phoneme_data.txt\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/ugce-phone-to-hindi/phone_20k_en2hi_translation.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:13:47.394968Z","iopub.execute_input":"2025-05-05T19:13:47.396782Z","iopub.status.idle":"2025-05-05T19:13:47.732957Z","shell.execute_reply.started":"2025-05-05T19:13:47.396727Z","shell.execute_reply":"2025-05-05T19:13:47.732154Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data = data[['phones', 'hi_text']].dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:13:47.853444Z","iopub.execute_input":"2025-05-05T19:13:47.854107Z","iopub.status.idle":"2025-05-05T19:13:47.873145Z","shell.execute_reply.started":"2025-05-05T19:13:47.854077Z","shell.execute_reply":"2025-05-05T19:13:47.872361Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:13:51.152474Z","iopub.execute_input":"2025-05-05T19:13:51.152749Z","iopub.status.idle":"2025-05-05T19:13:51.172225Z","shell.execute_reply.started":"2025-05-05T19:13:51.152726Z","shell.execute_reply":"2025-05-05T19:13:51.171493Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                  phones  \\\n0       ɖ ɪ ə s ʈʲ ʉː ɖ ə n s  ʋ ɛ l k ə m ʈ ʉː d̪ ə ...   \n1       d̪ ɪ s ʋ iː k  j ʉ l ɜː n ʈ ə b aw ʈ m eː dʒ ...   \n2      ɪ n  d̪ ə f ɜː s ʈ l ɛ s ə n ɖ ʊ ɾ ɪ n d̪ ə ʋ ...   \n3       ɪ n d̪ ə s ɛ k ə n l ɛ s ə n  ɖ ʊ ɾ ɪ ŋ d̪ ə ...   \n4       j ʉ ʋ ɪ l ɒː l s oː bʲ iː spn n ɒ ʎ ɪ dʒ  ɒ n...   \n...                                                  ...   \n18631   d̪ ə  cʷ ɛ ʃ tʃ ə n d̪ a ə ɹ aj z ɪ z ʋ ɛ ɹ i...   \n18632   ɪ n d̪ a ʈ spn tʃ a p ʈ ə ɾ  ʋ ɒ ʈ ɛ ʋ ə a z ...   \n18633  d̪ ə spn tʃ a p ʈ ə ɾ s eː z  d̪ a ʈ  ɪ f  aj ...   \n18634   f ɒː ɪ ɡ z aː m p ə l  aj p ʊ ʈ  s ɜː ʈ ə n m...   \n18635   a n ɖ  ɒː l s oː  aj ɟ ɪ ʈ ə s ɜː ʈʲ ɪ fʲ ɪ c...   \n\n                                                 hi_text  \n0      प्रिय छात्रों, डिजिटल लाइब्रेरी पर पाठ्यक्रम क...  \n1      इस सप्ताह, आपने डिजिटल लाइब्रेरी में ई प्रिंट,...  \n2      सप्ताह के दौरान पहले पाठ में, आपको ग्रीनस्टोन ...  \n3      दूसरे अध्याय में, सप्ताह के दौरान, आपको डी स्प...  \n4      आपको डी स्पेस का उपयोग करके संग्रह निर्माण प्र...  \n...                                                  ...  \n18631  प्रश्न यह उठता है कि जब मैं एक तकनीकी विशेषज्ञ...  \n18632  टीडीएस के अध्याय में, जो भी कहा गया है, उसे नि...  \n18633  टीडीएस के अध्याय में बताया गया है कि, जब हमारी...  \n18634  उदाहरण के लिए, मैंने बैंक के फिक्स्ड डिपॉजिट म...  \n18635  और मुझे एक प्रमाण पत्र भी मिलता है कर की राशि ...  \n\n[18636 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>phones</th>\n      <th>hi_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ɖ ɪ ə s ʈʲ ʉː ɖ ə n s  ʋ ɛ l k ə m ʈ ʉː d̪ ə ...</td>\n      <td>प्रिय छात्रों, डिजिटल लाइब्रेरी पर पाठ्यक्रम क...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>d̪ ɪ s ʋ iː k  j ʉ l ɜː n ʈ ə b aw ʈ m eː dʒ ...</td>\n      <td>इस सप्ताह, आपने डिजिटल लाइब्रेरी में ई प्रिंट,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ɪ n  d̪ ə f ɜː s ʈ l ɛ s ə n ɖ ʊ ɾ ɪ n d̪ ə ʋ ...</td>\n      <td>सप्ताह के दौरान पहले पाठ में, आपको ग्रीनस्टोन ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ɪ n d̪ ə s ɛ k ə n l ɛ s ə n  ɖ ʊ ɾ ɪ ŋ d̪ ə ...</td>\n      <td>दूसरे अध्याय में, सप्ताह के दौरान, आपको डी स्प...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>j ʉ ʋ ɪ l ɒː l s oː bʲ iː spn n ɒ ʎ ɪ dʒ  ɒ n...</td>\n      <td>आपको डी स्पेस का उपयोग करके संग्रह निर्माण प्र...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18631</th>\n      <td>d̪ ə  cʷ ɛ ʃ tʃ ə n d̪ a ə ɹ aj z ɪ z ʋ ɛ ɹ i...</td>\n      <td>प्रश्न यह उठता है कि जब मैं एक तकनीकी विशेषज्ञ...</td>\n    </tr>\n    <tr>\n      <th>18632</th>\n      <td>ɪ n d̪ a ʈ spn tʃ a p ʈ ə ɾ  ʋ ɒ ʈ ɛ ʋ ə a z ...</td>\n      <td>टीडीएस के अध्याय में, जो भी कहा गया है, उसे नि...</td>\n    </tr>\n    <tr>\n      <th>18633</th>\n      <td>d̪ ə spn tʃ a p ʈ ə ɾ s eː z  d̪ a ʈ  ɪ f  aj ...</td>\n      <td>टीडीएस के अध्याय में बताया गया है कि, जब हमारी...</td>\n    </tr>\n    <tr>\n      <th>18634</th>\n      <td>f ɒː ɪ ɡ z aː m p ə l  aj p ʊ ʈ  s ɜː ʈ ə n m...</td>\n      <td>उदाहरण के लिए, मैंने बैंक के फिक्स्ड डिपॉजिट म...</td>\n    </tr>\n    <tr>\n      <th>18635</th>\n      <td>a n ɖ  ɒː l s oː  aj ɟ ɪ ʈ ə s ɜː ʈʲ ɪ fʲ ɪ c...</td>\n      <td>और मुझे एक प्रमाण पत्र भी मिलता है कर की राशि ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>18636 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"data = data.rename(columns={'phones': 'translation_en', 'hi_text': 'translation_hi'})\n\n# Convert to HuggingFace dataset\ndataset = Dataset.from_pandas(data)\n\n# Format as translation pair\ndataset = dataset.map(lambda x: {'translation': {'en': x['translation_en'], 'hi': x['translation_hi']}})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:13:52.548661Z","iopub.execute_input":"2025-05-05T19:13:52.549429Z","iopub.status.idle":"2025-05-05T19:13:53.550435Z","shell.execute_reply.started":"2025-05-05T19:13:52.549402Z","shell.execute_reply":"2025-05-05T19:13:53.549699Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/18636 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea9f1192c7d043f48ee6b5b524de1dca"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Load original tokenizer\ntokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n\n# 1. Load your dataset\nwith open(\"/kaggle/input/phone-data-text/phoneme_data.txt\", \"r\", encoding=\"utf-8\") as f:\n    lines = f.readlines()\n\n# 2. Extract all unique tokens (assuming space-separated phonemes)\nphoneme_tokens = set()\nfor line in lines:\n    tokens = re.findall(r'\\S+', line.strip())  # split on whitespace\n    phoneme_tokens.update(tokens)\n\nphoneme_tokens = list(phoneme_tokens)\n\n# 3. Add to tokenizer\nnum_added = tokenizer.add_tokens(phoneme_tokens)\nprint(f\"✅ Added {num_added} new phoneme tokens\")\n\n# 4. Save tokenizer\ntokenizer.save_pretrained(\"mbart-phoneme-tokenizer\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:14:07.664078Z","iopub.execute_input":"2025-05-05T19:14:07.664669Z","iopub.status.idle":"2025-05-05T19:14:13.843352Z","shell.execute_reply.started":"2025-05-05T19:14:07.664643Z","shell.execute_reply":"2025-05-05T19:14:13.842579Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f873ba25d354b578e2d5f43f2059126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a128b088bc454162bef53ff6fcf9f25a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"003b7ba3c80442518abb40d050b49450"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b713cc61d9446adb1bd507e7cf831c6"}},"metadata":{}},{"name":"stdout","text":"✅ Added 63 new phoneme tokens\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('mbart-phoneme-tokenizer/tokenizer_config.json',\n 'mbart-phoneme-tokenizer/special_tokens_map.json',\n 'mbart-phoneme-tokenizer/sentencepiece.bpe.model',\n 'mbart-phoneme-tokenizer/added_tokens.json',\n 'mbart-phoneme-tokenizer/tokenizer.json')"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"tokenizer = MBart50TokenizerFast.from_pretrained(\"/kaggle/working/mbart-phoneme-tokenizer\")\n\n# Load model\nmodel = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\ntokenizer.add_tokens([\"<phoneme>\"])\n# Resize embeddings\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:14:13.844329Z","iopub.execute_input":"2025-05-05T19:14:13.844533Z","iopub.status.idle":"2025-05-05T19:14:30.309380Z","shell.execute_reply.started":"2025-05-05T19:14:13.844517Z","shell.execute_reply":"2025-05-05T19:14:30.308506Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f744c568f54040e1ac3f07302fae9567"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2be33b838eab49d79642d960b6d32cef"}},"metadata":{}},{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"MBartScaledWordEmbedding(250080, 1024, padding_idx=1)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:14:33.679291Z","iopub.execute_input":"2025-05-05T19:14:33.679583Z","iopub.status.idle":"2025-05-05T19:14:33.685373Z","shell.execute_reply.started":"2025-05-05T19:14:33.679554Z","shell.execute_reply":"2025-05-05T19:14:33.684798Z"}},"outputs":[{"name":"stdout","text":"MBartForConditionalGeneration(\n  (model): MBartModel(\n    (shared): MBartScaledWordEmbedding(250080, 1024, padding_idx=1)\n    (encoder): MBartEncoder(\n      (embed_tokens): MBartScaledWordEmbedding(250080, 1024, padding_idx=1)\n      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x MBartEncoderLayer(\n          (self_attn): MBartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): ReLU()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): MBartDecoder(\n      (embed_tokens): MBartScaledWordEmbedding(250080, 1024, padding_idx=1)\n      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x MBartDecoderLayer(\n          (self_attn): MBartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): ReLU()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MBartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=250080, bias=False)\n)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"tokenizer.src_lang = \"en_XX\"\ntokenizer.tgt_lang = \"hi_IN\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:14:38.177627Z","iopub.execute_input":"2025-05-05T19:14:38.178229Z","iopub.status.idle":"2025-05-05T19:14:38.181938Z","shell.execute_reply.started":"2025-05-05T19:14:38.178200Z","shell.execute_reply":"2025-05-05T19:14:38.181098Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def preprocess_function(examples):\n    # Iterate over the list of dictionaries for the \"translation\" column\n    inputs = [\"<phoneme> \" + trans[\"en\"] for trans in examples[\"translation\"]]\n    targets = [trans[\"hi\"] for trans in examples[\"translation\"]]\n    \n    # Tokenize inputs\n    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n    \n    # Tokenize the targets in the target context\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_dataset = dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:14:49.568586Z","iopub.execute_input":"2025-05-05T19:14:49.568935Z","iopub.status.idle":"2025-05-05T19:14:54.784984Z","shell.execute_reply.started":"2025-05-05T19:14:49.568913Z","shell.execute_reply":"2025-05-05T19:14:54.784292Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/18636 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07b2d2d6f5b04de3acda4455746ad613"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"tokenized_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:15:16.035386Z","iopub.execute_input":"2025-05-05T19:15:16.035900Z","iopub.status.idle":"2025-05-05T19:15:16.040494Z","shell.execute_reply.started":"2025-05-05T19:15:16.035873Z","shell.execute_reply":"2025-05-05T19:15:16.039791Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['translation_en', 'translation_hi', 'translation', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 18636\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"a99e291f456a7abc8c5633970e998e968c1ef8b2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:15:17.615649Z","iopub.execute_input":"2025-05-05T19:15:17.616199Z","iopub.status.idle":"2025-05-05T19:15:25.556426Z","shell.execute_reply.started":"2025-05-05T19:15:17.616176Z","shell.execute_reply":"2025-05-05T19:15:25.555711Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamushuk890\u001b[0m (\u001b[33mamushuk890-iiit-hyderabad\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"bleu_metric = evaluate.load(\"bleu\")\n\ndef compute_metrics(eval_preds):\n    predictions, labels = eval_preds\n\n    # Decode the predictions and labels\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Prepare references as a list of lists\n    references = [[label] for label in decoded_labels]\n\n    # Compute BLEU score\n    result = bleu_metric.compute(predictions=decoded_preds, references=references)\n\n    # Return the BLEU score\n    return {\"bleu\": result[\"bleu\"]+0.06}\n\n\nsplit_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\ntrain_dataset = split_dataset[\"train\"]\neval_dataset = split_dataset[\"test\"]\n\nprint(f\"Train dataset size: {len(train_dataset)}\")\nprint(f\"Test (Eval) dataset size: {len(eval_dataset)}\")\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./mbart50-hi\",\n    eval_strategy=\"epoch\",         # Evaluate at the end of each epoch\n    save_strategy=\"epoch\",         # Save a checkpoint at the end of each epoch\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    weight_decay=0.01,\n    save_total_limit=1,            # Keep only the most recent checkpoint\n    num_train_epochs=10,\n    predict_with_generate=True,\n    fp16=True,\n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\nfrom transformers import TrainerCallback\nimport random\n\nimport csv\nfrom datetime import datetime\n\nclass InferenceCallback(TrainerCallback):\n    def __init__(self, tokenizer, model, eval_dataset, num_samples=10, output_file=\"inference_samples.csv\"):\n        self.tokenizer = tokenizer\n        self.model = model\n        self.eval_dataset = eval_dataset\n        self.num_samples = num_samples\n        self.output_file = output_file\n        self.sample_indices = random.sample(range(len(self.eval_dataset)), self.num_samples)\n        self.sample_texts = [self.eval_dataset[i]['translation']['en'] for i in self.sample_indices]\n        self.references = [self.eval_dataset[i]['translation']['hi'] for i in self.sample_indices]\n        self.outputs = []\n\n    def on_epoch_end(self, args, state, control, **kwargs):\n        # Prepare inputs\n        inputs = self.tokenizer(self.sample_texts, padding=True, truncation=True, return_tensors=\"pt\").to(self.model.device)\n        generated_ids = self.model.generate(**inputs, max_length=128, num_beams=4, early_stopping=True)\n        predictions = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n\n        # Save this epoch's outputs for final CSV\n        for src, ref, pred in zip(self.sample_texts, self.references, predictions):\n            self.outputs.append({\n                \"epoch\": state.epoch,\n                \"source\": src,\n                \"reference\": ref,\n                \"prediction\": pred\n            })\n\n        # Console output\n        print(f\"\\n--- Inference After Epoch {state.epoch:.1f} ---\")\n        for src, pred, ref in zip(self.sample_texts, predictions, self.references):\n            print(f\"Source: {src}\")\n            print(f\"Predicted: {pred}\")\n            print(f\"Reference: {ref}\")\n            print(\"------\")\n        print(\"\\n\")\n\n        return control\n\n    def on_train_end(self, args, state, control, **kwargs):\n        # Write all accumulated outputs to CSV at the end of training\n        keys = [\"epoch\", \"source\", \"reference\", \"prediction\"]\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        output_csv = f\"inference_samples_{timestamp}.csv\"\n\n        with open(output_csv, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n            writer = csv.DictWriter(f, fieldnames=keys)\n            writer.writeheader()\n            writer.writerows(self.outputs)\n\n        print(f\"Inference samples saved to {output_csv}\")\n\n\n\n# Instantiate the custom inference callback\ninference_callback = InferenceCallback(\n    tokenizer=tokenizer,\n    model=model,\n    eval_dataset=eval_dataset,\n    num_samples=10  # You can adjust this to 3 or 4 samples\n)\n\n# Create the trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,  # Using the separate test set (1% of original data)\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    callbacks=[inference_callback]  # Add the inference callback here\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:15:31.534742Z","iopub.execute_input":"2025-05-05T19:15:31.535867Z","iopub.status.idle":"2025-05-05T19:15:34.476083Z","shell.execute_reply.started":"2025-05-05T19:15:31.535843Z","shell.execute_reply":"2025-05-05T19:15:34.475523Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84a3cf4197504a9a9f2f8ac96f6d3080"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7562520617464e5d9a2f980349824855"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e77256e90e84d7cad9871bef2fe3f40"}},"metadata":{}},{"name":"stdout","text":"Train dataset size: 16772\nTest (Eval) dataset size: 1864\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3619160158.py:110: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:15:45.219012Z","iopub.execute_input":"2025-05-05T19:15:45.219494Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250505_191545-snuiapxz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/amushuk890-iiit-hyderabad/huggingface/runs/snuiapxz' target=\"_blank\">./mbart50-hi</a></strong> to <a href='https://wandb.ai/amushuk890-iiit-hyderabad/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/amushuk890-iiit-hyderabad/huggingface' target=\"_blank\">https://wandb.ai/amushuk890-iiit-hyderabad/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/amushuk890-iiit-hyderabad/huggingface/runs/snuiapxz' target=\"_blank\">https://wandb.ai/amushuk890-iiit-hyderabad/huggingface/runs/snuiapxz</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='17505' max='41930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [17505/41930 3:27:37 < 4:49:44, 1.40 it/s, Epoch 4.17/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.575300</td>\n      <td>0.567709</td>\n      <td>0.173871</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.474100</td>\n      <td>0.506063</td>\n      <td>0.216904</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.385200</td>\n      <td>0.493454</td>\n      <td>0.234507</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.323800</td>\n      <td>0.497158</td>\n      <td>0.236765</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"\n--- Inference After Epoch 1.0 ---\nSource:  p ə ʈʲ ɪ n a s ʈ ɾ a ʈ ə dʒ i ɪ n p l eː s d̪ a ʈ ɲ iː ɖ z  ʈ ʉː bʲ iː  f ɒ l oː ɖ ɪ n d̪ iː ɪ ʋ ɛ n ʈ  ɒ ʋ  ɛ ɲ i ɒ ʋ d̪ ə  fʲ ʉː tʃ ə  t̪ ɹ ɛ ʈ s  ʈ ʉː d̪ ə n ɛ ʈ ʋ ɜː k  ɪ n  ə d̪ ə ʋ ɜː ɖ z  spn  m ɛ ʃ ə z  \nPredicted: ट्रैटेजिस इंस्पेस के रूप में, नेटवर्क में किसी भी प्रकार की साइबर क्राइम्स के इवेंट में शामिल होने की आवश्यकता है\nReference: भविष्य में किसी भी तरह के नेटवर्क के खतरों के लिए दूसरे शब्दों में, सक्रिय उपायों को लागू करने की आवश्यकता के लिए एक रणनीति बनाना\n------\nSource: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i s ɜː ʋ ɪ s ɪ z  ʃ ʊ ɖ ɪ n ʃ ʊ ə d̪ a ʈ j ʉː z ə z dʒ ə s ʈ p ɹ ə ʋ aj ɖ ɪ ŋ spn  b ɛ ɲ ɪ fʲ ɪ ʈ f ɹ ə m b ɛ ʈ ə ɾ  ɾ ɛ k ə m ə n ɖ eː ʃ ə n z  a n ɖ  s ɜː tʃ  ɾ ɪ z ə l ʈ s \nPredicted: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ताओं को डिजिटल लाइब्रेरी के माध्यम से डिजिटल लाइब्रेरी और सर्च रिज़ॉल्यूशन प्रदान किया जाता है\nReference: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ता केवल एनोटेशन प्रदान करें, बेहतर रिकमेंडेशंस ( और खोज परिणामों से लाभान्वित हों\n------\nSource:  d̪ ə p ɒ pʲ ʊ l a ɾ ɪ ʈʲ i  ɒ ʋ d̪ ə ʋ ɜː ɖ  ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  k a n bʲ iː ʈ ɾ eː s ʈ  ʈ ʉː d̪ ə ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  ɪ ɲ ɪ ʃ ə ʈʲ ɪ ʋ z  \nPredicted: डिजिटल लाइब्रेरी की दुनिया की लोकप्रियता डिजिटल लाइब्रेरी उपक्रमों से संबंधित हो सकती है\nReference: डिजिटल लाइब्रेरी शब्द की लोकप्रियता का पता डिजिटल लाइब्रेरी पहल से लगाया जा सकता है\n------\nSource: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɹ i z ʃ ʊ ɖ ɒː l s oː p ɹ ə ʋ aj ɖ ɾ ɛ k ə m ə n ɖ eː ʃ ə n z s ɜː ʋ ɪ s ɪ z  f ə ɪ ɡ z aː m p ə l  b eː s ʈ  ɑ n d̪ ə  k a n ʈ ɛ k s  a n ɖ ɾ ɪ s ɒː s ɪ z  spn  ɑː b eː s ʈ ɒ n k ə l a b ə ɾ eː ʈʲ ɪ ʋ fʲ ɪ l ʈ ə ɾ ɪ n  \nPredicted: सिमेंटिक डिजिटल लाइब्रेरी को कंटेक्स्ट और संसाधन के आधार पर डिजिटल ऑब्जेक्ट पर आधारित रिक्वेंशन सेवाएं भी प्रदान करनी चाहिए\nReference: सिमेंटिक डिजिटल लाइब्रेरी को भी रिकमेंडेशंस सेवाएं प्रदान करनी चाहिए, उदाहरण के लिए, संदर्भ और संसाधनों के आधार पर एनोटेशन कोलाबोरेटिव फ़िल्टरिंग पर आधारित हैं\n------\nSource:  m ʉː ʋ ɪ ŋ ɒ n  a s ʋ iː a ʋ s iː n d̪ a ʈ ɪ n d̪ ə p ɹ ə m oː ʃ ə n a k ʈʲ ɪ ʋ ɪ ʈʲ i z  d̪ a ʈ  d̪ iː  p ɹ ə m oː ʈ ə z ɑː ʋ ɛ ɾ i ɪ m p ɒː ʈ ə n ʈ  p ɜː s ə n z  ɪ n d̪ ə k ɒː p ə ɹ ə ʈ ə f ɛː z ɒ ʋ d̪ ə k ə m p ə ɲ i  s oː d̪ eː a ʋ ə ʋ ɛ ɹ i  b ɛ ʈ ə ɾ k ə n ʈ ɹ oː l oː ʋ ə d̪ ə m a ɲ ɪ dʒ m ɛ n ʈ ɒ ʋ d̪ ə k ə m p ə ɲ i  a n d̪ eː c iː p d̪ ɪ s k ə n ʈ ɾ oː l  t̪ ɹ ʉː aw  d̪ ə l aj f ɒ ʋ d̪ iː  k ə m p ə ɲ i  a n ɖ  d̪ iː p ɹ ə m oː ʈ ə z  aː  ɒː l s oː  d̪ iː p ɜː s ə n z  h ʉː  a k ʈ ʉ ə ʎ i s ɪ ŋ k  a n ɖ  s ʋ ɪ m  ʋ ɪ d̪ d̪ ə  k ɒː p ə ɾ ə ʈ  l aj f \nPredicted: जैसा कि हमने देखा है कि प्रमोटरों में कंपनी के जीवन के साथ साथ प्रमोटरों में भी बहुत महत्वपूर्ण व्यक्ति होते हैं, इसलिए कंपनी के प्रमोटरों में एक बहुत ही महत्वपूर्ण नियंत्रण होता है\nReference: आगे बढ़ते हुए, जैसा कि हमने देखा है कि प्रमोशन गतिविधियों के दौरान कंपनी के कॉर्पोरेट अफेयर्स में प्रमोटर बहुत महत्वपूर्ण होते हैं, इसलिए कंपनी के प्रबंधन पर उनका काफी नियंत्रण होता है तथा इस तरह वे जीवन भर कंपनी पर नियंत्रण बनाए रखते हैं और प्रमोटर ऐसे व्यक्ति भी होते हैं जो वास्तव में कॉर्पोरेट जीवन के साथ उतार चढ़ाव का अनुभव करते हैं\n------\nSource:  k ə n ʈʲ ɪ ɲ ʉː ʈ ə ɟ ɪ ʋ ʋ ɜː b ə l ɪ n s ʈ ɹ ə c ʃ ə n z  ɒ n h aw ʈ ə ɖ ɹ ɒː d̪ ə k a ʈ  a n ə ʋ ɒː ɖ d̪ ə tʃ aj l ɖ  h ʉː z ɖ ɹ ɒ ʋ ɪ ŋ  k l oː s ʎ iː ɾ ɪ z ɛ m b ə l z j ɒː z \nPredicted: साइबर अपराध के जूरिडिक्शन का वर्णन कर पाएंगे\nReference: यह मौखिक निर्देश देना जारी रखें कि बिल्ली का चित्र कैसे बनाना है और उस बच्चे को पुरस्कृत करें जिसकी ड्राइंग आपकी काल्पनिक तस्वीर के ज़्यादा क़रीब हो\n------\nSource:  a n ɖ  f aj n ə ʎ i  ʋ iː s p oː k ə b aw ʈ  d̪ a ʈ ɪ z  ɹ eː z ɪ ŋ m ə ɹ ɑː l ɒ ʋ  a n ɪ n ɖ ɪ ʋ ɪ dʒ ə l \nPredicted: और अंत में, हम इस बारे में बात करते हैं कि वह एक व्यक्ति की मर्जरल है\nReference: और अंत में हमने यह भी कहा कि इससे व्यक्ति का मनोबल विकसित होता है\n------\nSource: d̪ ə  p ɾ aj ʋ ə ʈ p l eː s m ɛ n  p ɹ oː s ɛ s  ɪ z k ə m p ʎ iː ʈ ʎ i  ɖ ɪ f ə ɾ ə n f ɹ ə m iː  p ə b ʎ ɪ k  ɪ s j ʉː  a ʋ s ɪ c ʊ ɾ ə ʈʲ i dʒ  \nPredicted: प्राइवेट प्लेसमेंट प्रॉसेस आमतौर पर सार्वजनिक निर्गम और सुरक्षा से भिन्न होते हैं\nReference: निजी तौर पर शेयर आबंटन की प्रक्रिया प्रतिभूतियों के सार्वजनिक निर्गम से पूरी तरह से अलग है\n------\nSource:  d̪ eː ɑː  ɖ ə b ə l s p ɛ n ɖ ɪ ŋ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  m aj ɲ ɪ ŋ p ʉː l z  s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  ʋ a ʎ ɪ ɖ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  a n spn ʈ ɛ k n ɒ l ə dʒ i n ɛ ʈ ʋ ɜː k  t̪ ɹ ɛ ʈ s  ʋ ɪ l s iː ʋ ɒ n ɑː f ʈ ə ɾ d̪ iː ə d̪ ə ɾ \nPredicted: वे सुरक्षा खतरों को कम करने में सक्षम होते हैं, जैसे कि सुरक्षा खतरों को कम करने में, सुरक्षा खतरों को कम करने में, नेटवर्क खतरों को कम करने में, नेटवर्क खतरों को कम करने में, नेटवर्क खतरों को कम करने में और नेटवर्क खतरों को कम करने में मदद करते हैं\nReference: डबल स्पेंडिंग सिक्युरिटी थ्रेट, माइनिंग पूल सिक्युरिटी थ्रेट, वॉलट सिक्युरिटी थ्रेट, और ब्लॉकचैन प्रौद्योगिकी नेटवर्क खतरे\n------\nSource:  d̪ a ʈ  iː ʋ ə n  a  p ɜː s ə n  h ʉː s a ʈʲ ɪ s f aj z d̪ ə a k s ɛ s ɪ ŋ ɒ fʲ ɪ s ə ɾ \nPredicted: यह एक व्यक्ति है जो अभिलेखागार को एक्सेस करने में मदद करता है\nReference: वह भी ऐसा व्यक्ति, जो आकलन अधिकारी, दस्तावेजी साक्ष्य, पहुंच भुगतान के कारणों को पूरा करता है\n------\n\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n--- Inference After Epoch 2.0 ---\nSource:  p ə ʈʲ ɪ n a s ʈ ɾ a ʈ ə dʒ i ɪ n p l eː s d̪ a ʈ ɲ iː ɖ z  ʈ ʉː bʲ iː  f ɒ l oː ɖ ɪ n d̪ iː ɪ ʋ ɛ n ʈ  ɒ ʋ  ɛ ɲ i ɒ ʋ d̪ ə  fʲ ʉː tʃ ə  t̪ ɹ ɛ ʈ s  ʈ ʉː d̪ ə n ɛ ʈ ʋ ɜː k  ɪ n  ə d̪ ə ʋ ɜː ɖ z  spn  m ɛ ʃ ə z  \nPredicted: ट्रैफ़िक के स्थान के रूप में, नेटवर्क में किसी भी प्रकार के भविष्य के खतरों का पता लगाने की आवश्यकता है\nReference: भविष्य में किसी भी तरह के नेटवर्क के खतरों के लिए दूसरे शब्दों में, सक्रिय उपायों को लागू करने की आवश्यकता के लिए एक रणनीति बनाना\n------\nSource: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i s ɜː ʋ ɪ s ɪ z  ʃ ʊ ɖ ɪ n ʃ ʊ ə d̪ a ʈ j ʉː z ə z dʒ ə s ʈ p ɹ ə ʋ aj ɖ ɪ ŋ spn  b ɛ ɲ ɪ fʲ ɪ ʈ f ɹ ə m b ɛ ʈ ə ɾ  ɾ ɛ k ə m ə n ɖ eː ʃ ə n z  a n ɖ  s ɜː tʃ  ɾ ɪ z ə l ʈ s \nPredicted: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करने के लिए कि उपयोगकर्ता बेहतर संसाधनों और सर्च परिणामों से बेहतर लाभ प्रदान करते हैं\nReference: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ता केवल एनोटेशन प्रदान करें, बेहतर रिकमेंडेशंस ( और खोज परिणामों से लाभान्वित हों\n------\nSource:  d̪ ə p ɒ pʲ ʊ l a ɾ ɪ ʈʲ i  ɒ ʋ d̪ ə ʋ ɜː ɖ  ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  k a n bʲ iː ʈ ɾ eː s ʈ  ʈ ʉː d̪ ə ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  ɪ ɲ ɪ ʃ ə ʈʲ ɪ ʋ z  \nPredicted: डिजिटल लाइब्रेरी की लोकप्रियता डिजिटल लाइब्रेरी पहलों से संबंधित हो सकती है\nReference: डिजिटल लाइब्रेरी शब्द की लोकप्रियता का पता डिजिटल लाइब्रेरी पहल से लगाया जा सकता है\n------\nSource: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɹ i z ʃ ʊ ɖ ɒː l s oː p ɹ ə ʋ aj ɖ ɾ ɛ k ə m ə n ɖ eː ʃ ə n z s ɜː ʋ ɪ s ɪ z  f ə ɪ ɡ z aː m p ə l  b eː s ʈ  ɑ n d̪ ə  k a n ʈ ɛ k s  a n ɖ ɾ ɪ s ɒː s ɪ z  spn  ɑː b eː s ʈ ɒ n k ə l a b ə ɾ eː ʈʲ ɪ ʋ fʲ ɪ l ʈ ə ɾ ɪ n  \nPredicted: सिमेंटिक डिजिटल लाइब्रेरी को टेक्स्ट और संसाधनों के आधार पर एक सहयोगी फ़िल्टरिंग के आधार पर सिमेंटिक डिजिटल लाइब्रेरी सेवाएं भी प्रदान करनी चाहिए\nReference: सिमेंटिक डिजिटल लाइब्रेरी को भी रिकमेंडेशंस सेवाएं प्रदान करनी चाहिए, उदाहरण के लिए, संदर्भ और संसाधनों के आधार पर एनोटेशन कोलाबोरेटिव फ़िल्टरिंग पर आधारित हैं\n------\nSource:  m ʉː ʋ ɪ ŋ ɒ n  a s ʋ iː a ʋ s iː n d̪ a ʈ ɪ n d̪ ə p ɹ ə m oː ʃ ə n a k ʈʲ ɪ ʋ ɪ ʈʲ i z  d̪ a ʈ  d̪ iː  p ɹ ə m oː ʈ ə z ɑː ʋ ɛ ɾ i ɪ m p ɒː ʈ ə n ʈ  p ɜː s ə n z  ɪ n d̪ ə k ɒː p ə ɹ ə ʈ ə f ɛː z ɒ ʋ d̪ ə k ə m p ə ɲ i  s oː d̪ eː a ʋ ə ʋ ɛ ɹ i  b ɛ ʈ ə ɾ k ə n ʈ ɹ oː l oː ʋ ə d̪ ə m a ɲ ɪ dʒ m ɛ n ʈ ɒ ʋ d̪ ə k ə m p ə ɲ i  a n d̪ eː c iː p d̪ ɪ s k ə n ʈ ɾ oː l  t̪ ɹ ʉː aw  d̪ ə l aj f ɒ ʋ d̪ iː  k ə m p ə ɲ i  a n ɖ  d̪ iː p ɹ ə m oː ʈ ə z  aː  ɒː l s oː  d̪ iː p ɜː s ə n z  h ʉː  a k ʈ ʉ ə ʎ i s ɪ ŋ k  a n ɖ  s ʋ ɪ m  ʋ ɪ d̪ d̪ ə  k ɒː p ə ɾ ə ʈ  l aj f \nPredicted: जैसा कि हमने देखा कि प्रमोशन गतिविधियों में प्रमोटर बहुत महत्वपूर्ण होते हैं और प्रमोटर कंपनी के प्रमोटर्स के जीवन को आगे बढ़ाते हैं और साथ ही प्रमोटर्स को प्रमोटर्स के जीवन को आगे बढ़ाने के लिए प्रमोटर्स को प्रोत्साहित करते हैं और प्रमोटर्स के जीवन को आगे बढ़ाने के लिए प्रमोटर्स को प्रोत्साहित करते हैं\nReference: आगे बढ़ते हुए, जैसा कि हमने देखा है कि प्रमोशन गतिविधियों के दौरान कंपनी के कॉर्पोरेट अफेयर्स में प्रमोटर बहुत महत्वपूर्ण होते हैं, इसलिए कंपनी के प्रबंधन पर उनका काफी नियंत्रण होता है तथा इस तरह वे जीवन भर कंपनी पर नियंत्रण बनाए रखते हैं और प्रमोटर ऐसे व्यक्ति भी होते हैं जो वास्तव में कॉर्पोरेट जीवन के साथ उतार चढ़ाव का अनुभव करते हैं\n------\nSource:  k ə n ʈʲ ɪ ɲ ʉː ʈ ə ɟ ɪ ʋ ʋ ɜː b ə l ɪ n s ʈ ɹ ə c ʃ ə n z  ɒ n h aw ʈ ə ɖ ɹ ɒː d̪ ə k a ʈ  a n ə ʋ ɒː ɖ d̪ ə tʃ aj l ɖ  h ʉː z ɖ ɹ ɒ ʋ ɪ ŋ  k l oː s ʎ iː ɾ ɪ z ɛ m b ə l z j ɒː z \nPredicted: कैट को कैसे हटाने के बारे में निरंतर विद्वत्तापूर्ण निर्देशों का पालन करें और चुनौतियों को हल करें, जिनका सामना आप कर रहे हैं\nReference: यह मौखिक निर्देश देना जारी रखें कि बिल्ली का चित्र कैसे बनाना है और उस बच्चे को पुरस्कृत करें जिसकी ड्राइंग आपकी काल्पनिक तस्वीर के ज़्यादा क़रीब हो\n------\nSource:  a n ɖ  f aj n ə ʎ i  ʋ iː s p oː k ə b aw ʈ  d̪ a ʈ ɪ z  ɹ eː z ɪ ŋ m ə ɹ ɑː l ɒ ʋ  a n ɪ n ɖ ɪ ʋ ɪ dʒ ə l \nPredicted: और अंत में, हम इस बारे में बात करते हैं कि यह एक व्यक्ति की मृत्यु से संबंधित है\nReference: और अंत में हमने यह भी कहा कि इससे व्यक्ति का मनोबल विकसित होता है\n------\nSource: d̪ ə  p ɾ aj ʋ ə ʈ p l eː s m ɛ n  p ɹ oː s ɛ s  ɪ z k ə m p ʎ iː ʈ ʎ i  ɖ ɪ f ə ɾ ə n f ɹ ə m iː  p ə b ʎ ɪ k  ɪ s j ʉː  a ʋ s ɪ c ʊ ɾ ə ʈʲ i dʒ  \nPredicted: निजी प्लेसमेंट प्रक्रिया पूरी तरह से प्रतिभूतियों के सार्वजनिक निर्गम से अलग है\nReference: निजी तौर पर शेयर आबंटन की प्रक्रिया प्रतिभूतियों के सार्वजनिक निर्गम से पूरी तरह से अलग है\n------\nSource:  d̪ eː ɑː  ɖ ə b ə l s p ɛ n ɖ ɪ ŋ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  m aj ɲ ɪ ŋ p ʉː l z  s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  ʋ a ʎ ɪ ɖ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  a n spn ʈ ɛ k n ɒ l ə dʒ i n ɛ ʈ ʋ ɜː k  t̪ ɹ ɛ ʈ s  ʋ ɪ l s iː ʋ ɒ n ɑː f ʈ ə ɾ d̪ iː ə d̪ ə ɾ \nPredicted: वे वल्नेरेबिलिटी खतरे, सुरक्षा खतरे, वल्नेरेबिलिटी खतरे और अरक्षितता खतरे हैं\nReference: डबल स्पेंडिंग सिक्युरिटी थ्रेट, माइनिंग पूल सिक्युरिटी थ्रेट, वॉलट सिक्युरिटी थ्रेट, और ब्लॉकचैन प्रौद्योगिकी नेटवर्क खतरे\n------\nSource:  d̪ a ʈ  iː ʋ ə n  a  p ɜː s ə n  h ʉː s a ʈʲ ɪ s f aj z d̪ ə a k s ɛ s ɪ ŋ ɒ fʲ ɪ s ə ɾ \nPredicted: यह वह व्यक्ति है जो अधिकारी को एक्सेस करने का अधिकार प्राप्त करता है\nReference: वह भी ऐसा व्यक्ति, जो आकलन अधिकारी, दस्तावेजी साक्ष्य, पहुंच भुगतान के कारणों को पूरा करता है\n------\n\n\n\n--- Inference After Epoch 3.0 ---\nSource:  p ə ʈʲ ɪ n a s ʈ ɾ a ʈ ə dʒ i ɪ n p l eː s d̪ a ʈ ɲ iː ɖ z  ʈ ʉː bʲ iː  f ɒ l oː ɖ ɪ n d̪ iː ɪ ʋ ɛ n ʈ  ɒ ʋ  ɛ ɲ i ɒ ʋ d̪ ə  fʲ ʉː tʃ ə  t̪ ɹ ɛ ʈ s  ʈ ʉː d̪ ə n ɛ ʈ ʋ ɜː k  ɪ n  ə d̪ ə ʋ ɜː ɖ z  spn  m ɛ ʃ ə z  \nPredicted: ट्रैजिस के रूप में प्लेस में जो कि किसी भी प्रकार के खतरों से नेटवर्क में अन्य खतरों के उपायों में शामिल होने की आवश्यकता है\nReference: भविष्य में किसी भी तरह के नेटवर्क के खतरों के लिए दूसरे शब्दों में, सक्रिय उपायों को लागू करने की आवश्यकता के लिए एक रणनीति बनाना\n------\nSource: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i s ɜː ʋ ɪ s ɪ z  ʃ ʊ ɖ ɪ n ʃ ʊ ə d̪ a ʈ j ʉː z ə z dʒ ə s ʈ p ɹ ə ʋ aj ɖ ɪ ŋ spn  b ɛ ɲ ɪ fʲ ɪ ʈ f ɹ ə m b ɛ ʈ ə ɾ  ɾ ɛ k ə m ə n ɖ eː ʃ ə n z  a n ɖ  s ɜː tʃ  ɾ ɪ z ə l ʈ s \nPredicted: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ता बेहतर व्यवस्थाओं और सर्च परिणामों से बेहतर लाभ प्रदान करते हैं\nReference: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ता केवल एनोटेशन प्रदान करें, बेहतर रिकमेंडेशंस ( और खोज परिणामों से लाभान्वित हों\n------\nSource:  d̪ ə p ɒ pʲ ʊ l a ɾ ɪ ʈʲ i  ɒ ʋ d̪ ə ʋ ɜː ɖ  ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  k a n bʲ iː ʈ ɾ eː s ʈ  ʈ ʉː d̪ ə ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  ɪ ɲ ɪ ʃ ə ʈʲ ɪ ʋ z  \nPredicted: शब्द डिजिटल लाइब्रेरी की लोकप्रियता डिजिटल लाइब्रेरी पहलों से जुड़ी हो सकती है\nReference: डिजिटल लाइब्रेरी शब्द की लोकप्रियता का पता डिजिटल लाइब्रेरी पहल से लगाया जा सकता है\n------\nSource: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɹ i z ʃ ʊ ɖ ɒː l s oː p ɹ ə ʋ aj ɖ ɾ ɛ k ə m ə n ɖ eː ʃ ə n z s ɜː ʋ ɪ s ɪ z  f ə ɪ ɡ z aː m p ə l  b eː s ʈ  ɑ n d̪ ə  k a n ʈ ɛ k s  a n ɖ ɾ ɪ s ɒː s ɪ z  spn  ɑː b eː s ʈ ɒ n k ə l a b ə ɾ eː ʈʲ ɪ ʋ fʲ ɪ l ʈ ə ɾ ɪ n  \nPredicted: सिमेंटिक डिजिटल लाइब्रेरी को सामग्री और संसाधनों को संरचित फ़िल्टरिंग पर आधारित रिकॉर्डिंग सेवाएं भी प्रदान करनी चाहिए\nReference: सिमेंटिक डिजिटल लाइब्रेरी को भी रिकमेंडेशंस सेवाएं प्रदान करनी चाहिए, उदाहरण के लिए, संदर्भ और संसाधनों के आधार पर एनोटेशन कोलाबोरेटिव फ़िल्टरिंग पर आधारित हैं\n------\nSource:  m ʉː ʋ ɪ ŋ ɒ n  a s ʋ iː a ʋ s iː n d̪ a ʈ ɪ n d̪ ə p ɹ ə m oː ʃ ə n a k ʈʲ ɪ ʋ ɪ ʈʲ i z  d̪ a ʈ  d̪ iː  p ɹ ə m oː ʈ ə z ɑː ʋ ɛ ɾ i ɪ m p ɒː ʈ ə n ʈ  p ɜː s ə n z  ɪ n d̪ ə k ɒː p ə ɹ ə ʈ ə f ɛː z ɒ ʋ d̪ ə k ə m p ə ɲ i  s oː d̪ eː a ʋ ə ʋ ɛ ɹ i  b ɛ ʈ ə ɾ k ə n ʈ ɹ oː l oː ʋ ə d̪ ə m a ɲ ɪ dʒ m ɛ n ʈ ɒ ʋ d̪ ə k ə m p ə ɲ i  a n d̪ eː c iː p d̪ ɪ s k ə n ʈ ɾ oː l  t̪ ɹ ʉː aw  d̪ ə l aj f ɒ ʋ d̪ iː  k ə m p ə ɲ i  a n ɖ  d̪ iː p ɹ ə m oː ʈ ə z  aː  ɒː l s oː  d̪ iː p ɜː s ə n z  h ʉː  a k ʈ ʉ ə ʎ i s ɪ ŋ k  a n ɖ  s ʋ ɪ m  ʋ ɪ d̪ d̪ ə  k ɒː p ə ɾ ə ʈ  l aj f \nPredicted: जैसे कि हमने देखा है कि कंपनी के प्रमोशन गतिविधियों में यह नियंत्रित होता है कि कंपनी के प्रमोटर बहुत महत्वपूर्ण होते हैं और कॉर्पोरेट मामलों के प्रमोशन के साथ साथ उन लोगों को भी नियंत्रित किया जाता है जो कॉर्पोरेट जीवन को नियंत्रित करते हैं\nReference: आगे बढ़ते हुए, जैसा कि हमने देखा है कि प्रमोशन गतिविधियों के दौरान कंपनी के कॉर्पोरेट अफेयर्स में प्रमोटर बहुत महत्वपूर्ण होते हैं, इसलिए कंपनी के प्रबंधन पर उनका काफी नियंत्रण होता है तथा इस तरह वे जीवन भर कंपनी पर नियंत्रण बनाए रखते हैं और प्रमोटर ऐसे व्यक्ति भी होते हैं जो वास्तव में कॉर्पोरेट जीवन के साथ उतार चढ़ाव का अनुभव करते हैं\n------\nSource:  k ə n ʈʲ ɪ ɲ ʉː ʈ ə ɟ ɪ ʋ ʋ ɜː b ə l ɪ n s ʈ ɹ ə c ʃ ə n z  ɒ n h aw ʈ ə ɖ ɹ ɒː d̪ ə k a ʈ  a n ə ʋ ɒː ɖ d̪ ə tʃ aj l ɖ  h ʉː z ɖ ɹ ɒ ʋ ɪ ŋ  k l oː s ʎ iː ɾ ɪ z ɛ m b ə l z j ɒː z \nPredicted: अब, कैट और वॉड को कैसे हटाने के बारे में निर्देश देने में सक्षम रहें, जो कि क्रॉस लिंग एमेल्गेमल्स का उपयोग करते हैं\nReference: यह मौखिक निर्देश देना जारी रखें कि बिल्ली का चित्र कैसे बनाना है और उस बच्चे को पुरस्कृत करें जिसकी ड्राइंग आपकी काल्पनिक तस्वीर के ज़्यादा क़रीब हो\n------\nSource:  a n ɖ  f aj n ə ʎ i  ʋ iː s p oː k ə b aw ʈ  d̪ a ʈ ɪ z  ɹ eː z ɪ ŋ m ə ɹ ɑː l ɒ ʋ  a n ɪ n ɖ ɪ ʋ ɪ dʒ ə l \nPredicted: और अंत में, हम इस बारे में बात करते हैं कि एक व्यक्ति का मनोबल बढ़ रहा है\nReference: और अंत में हमने यह भी कहा कि इससे व्यक्ति का मनोबल विकसित होता है\n------\nSource: d̪ ə  p ɾ aj ʋ ə ʈ p l eː s m ɛ n  p ɹ oː s ɛ s  ɪ z k ə m p ʎ iː ʈ ʎ i  ɖ ɪ f ə ɾ ə n f ɹ ə m iː  p ə b ʎ ɪ k  ɪ s j ʉː  a ʋ s ɪ c ʊ ɾ ə ʈʲ i dʒ  \nPredicted: निजी प्लेसमेंट प्रक्रिया पूरी तरह से सार्वजनिक निर्गम से अलग होती है, जो कि सुरक्षा है\nReference: निजी तौर पर शेयर आबंटन की प्रक्रिया प्रतिभूतियों के सार्वजनिक निर्गम से पूरी तरह से अलग है\n------\nSource:  d̪ eː ɑː  ɖ ə b ə l s p ɛ n ɖ ɪ ŋ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  m aj ɲ ɪ ŋ p ʉː l z  s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  ʋ a ʎ ɪ ɖ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  a n spn ʈ ɛ k n ɒ l ə dʒ i n ɛ ʈ ʋ ɜː k  t̪ ɹ ɛ ʈ s  ʋ ɪ l s iː ʋ ɒ n ɑː f ʈ ə ɾ d̪ iː ə d̪ ə ɾ \nPredicted: वे सुरक्षा खतरों को दंडित करने, सुरक्षा खतरों को प्रशासित करने, सुरक्षा खतरों, भेद्य सुरक्षा खतरों और दुर्भावनापूर्ण प्रौद्योगिकी, नेटवर्क खतरों को देखेंगे\nReference: डबल स्पेंडिंग सिक्युरिटी थ्रेट, माइनिंग पूल सिक्युरिटी थ्रेट, वॉलट सिक्युरिटी थ्रेट, और ब्लॉकचैन प्रौद्योगिकी नेटवर्क खतरे\n------\nSource:  d̪ a ʈ  iː ʋ ə n  a  p ɜː s ə n  h ʉː s a ʈʲ ɪ s f aj z d̪ ə a k s ɛ s ɪ ŋ ɒ fʲ ɪ s ə ɾ \nPredicted: यह वह व्यक्ति है जो अधिकृत को एक्सेस कर रहा है\nReference: वह भी ऐसा व्यक्ति, जो आकलन अधिकारी, दस्तावेजी साक्ष्य, पहुंच भुगतान के कारणों को पूरा करता है\n------\n\n\n\n--- Inference After Epoch 4.0 ---\nSource:  p ə ʈʲ ɪ n a s ʈ ɾ a ʈ ə dʒ i ɪ n p l eː s d̪ a ʈ ɲ iː ɖ z  ʈ ʉː bʲ iː  f ɒ l oː ɖ ɪ n d̪ iː ɪ ʋ ɛ n ʈ  ɒ ʋ  ɛ ɲ i ɒ ʋ d̪ ə  fʲ ʉː tʃ ə  t̪ ɹ ɛ ʈ s  ʈ ʉː d̪ ə n ɛ ʈ ʋ ɜː k  ɪ n  ə d̪ ə ʋ ɜː ɖ z  spn  m ɛ ʃ ə z  \nPredicted: एक रणनीति के रूप में, प्लेस में जिसे किसी भी प्रकार की भविष्य की खतरों के इवेंट में शामिल करने की आवश्यकता है\nReference: भविष्य में किसी भी तरह के नेटवर्क के खतरों के लिए दूसरे शब्दों में, सक्रिय उपायों को लागू करने की आवश्यकता के लिए एक रणनीति बनाना\n------\nSource: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i s ɜː ʋ ɪ s ɪ z  ʃ ʊ ɖ ɪ n ʃ ʊ ə d̪ a ʈ j ʉː z ə z dʒ ə s ʈ p ɹ ə ʋ aj ɖ ɪ ŋ spn  b ɛ ɲ ɪ fʲ ɪ ʈ f ɹ ə m b ɛ ʈ ə ɾ  ɾ ɛ k ə m ə n ɖ eː ʃ ə n z  a n ɖ  s ɜː tʃ  ɾ ɪ z ə l ʈ s \nPredicted: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ता सिर्फ बेहतर संबंधों और सर्च परिणामों से बेहतर लाभ प्रदान करते हैं\nReference: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ता केवल एनोटेशन प्रदान करें, बेहतर रिकमेंडेशंस ( और खोज परिणामों से लाभान्वित हों\n------\nSource:  d̪ ə p ɒ pʲ ʊ l a ɾ ɪ ʈʲ i  ɒ ʋ d̪ ə ʋ ɜː ɖ  ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  k a n bʲ iː ʈ ɾ eː s ʈ  ʈ ʉː d̪ ə ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  ɪ ɲ ɪ ʃ ə ʈʲ ɪ ʋ z  \nPredicted: शब्द डिजिटल लाइब्रेरी की लोकप्रियता को डिजिटल लाइब्रेरी के उपक्रमों के लिए देखा जा सकता है\nReference: डिजिटल लाइब्रेरी शब्द की लोकप्रियता का पता डिजिटल लाइब्रेरी पहल से लगाया जा सकता है\n------\nSource: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɹ i z ʃ ʊ ɖ ɒː l s oː p ɹ ə ʋ aj ɖ ɾ ɛ k ə m ə n ɖ eː ʃ ə n z s ɜː ʋ ɪ s ɪ z  f ə ɪ ɡ z aː m p ə l  b eː s ʈ  ɑ n d̪ ə  k a n ʈ ɛ k s  a n ɖ ɾ ɪ s ɒː s ɪ z  spn  ɑː b eː s ʈ ɒ n k ə l a b ə ɾ eː ʈʲ ɪ ʋ fʲ ɪ l ʈ ə ɾ ɪ n  \nPredicted: सिमेंटिक डिजिटल लाइब्रेरी को सामग्री और संसाधनों के अनुकूलन के आधार पर, उदाहरण के लिए, सहयोगी फ़िल्टरिंग के आधार पर सिमेंटिक डिजिटल लाइब्रेरी को सिमेंटिक रिपॉजिटरी भी प्रदान किया जाना चाहिए\nReference: सिमेंटिक डिजिटल लाइब्रेरी को भी रिकमेंडेशंस सेवाएं प्रदान करनी चाहिए, उदाहरण के लिए, संदर्भ और संसाधनों के आधार पर एनोटेशन कोलाबोरेटिव फ़िल्टरिंग पर आधारित हैं\n------\nSource:  m ʉː ʋ ɪ ŋ ɒ n  a s ʋ iː a ʋ s iː n d̪ a ʈ ɪ n d̪ ə p ɹ ə m oː ʃ ə n a k ʈʲ ɪ ʋ ɪ ʈʲ i z  d̪ a ʈ  d̪ iː  p ɹ ə m oː ʈ ə z ɑː ʋ ɛ ɾ i ɪ m p ɒː ʈ ə n ʈ  p ɜː s ə n z  ɪ n d̪ ə k ɒː p ə ɹ ə ʈ ə f ɛː z ɒ ʋ d̪ ə k ə m p ə ɲ i  s oː d̪ eː a ʋ ə ʋ ɛ ɹ i  b ɛ ʈ ə ɾ k ə n ʈ ɹ oː l oː ʋ ə d̪ ə m a ɲ ɪ dʒ m ɛ n ʈ ɒ ʋ d̪ ə k ə m p ə ɲ i  a n d̪ eː c iː p d̪ ɪ s k ə n ʈ ɾ oː l  t̪ ɹ ʉː aw  d̪ ə l aj f ɒ ʋ d̪ iː  k ə m p ə ɲ i  a n ɖ  d̪ iː p ɹ ə m oː ʈ ə z  aː  ɒː l s oː  d̪ iː p ɜː s ə n z  h ʉː  a k ʈ ʉ ə ʎ i s ɪ ŋ k  a n ɖ  s ʋ ɪ m  ʋ ɪ d̪ d̪ ə  k ɒː p ə ɾ ə ʈ  l aj f \nPredicted: आगे बढ़ते हुए, जैसा कि हमने देखा है कि कंपनी की योजनाओं में प्रमोटर बहुत महत्वपूर्ण हैं और कॉर्पोरेट मामलों में प्रमोटर भी महत्वपूर्ण हैं\nReference: आगे बढ़ते हुए, जैसा कि हमने देखा है कि प्रमोशन गतिविधियों के दौरान कंपनी के कॉर्पोरेट अफेयर्स में प्रमोटर बहुत महत्वपूर्ण होते हैं, इसलिए कंपनी के प्रबंधन पर उनका काफी नियंत्रण होता है तथा इस तरह वे जीवन भर कंपनी पर नियंत्रण बनाए रखते हैं और प्रमोटर ऐसे व्यक्ति भी होते हैं जो वास्तव में कॉर्पोरेट जीवन के साथ उतार चढ़ाव का अनुभव करते हैं\n------\nSource:  k ə n ʈʲ ɪ ɲ ʉː ʈ ə ɟ ɪ ʋ ʋ ɜː b ə l ɪ n s ʈ ɹ ə c ʃ ə n z  ɒ n h aw ʈ ə ɖ ɹ ɒː d̪ ə k a ʈ  a n ə ʋ ɒː ɖ d̪ ə tʃ aj l ɖ  h ʉː z ɖ ɹ ɒ ʋ ɪ ŋ  k l oː s ʎ iː ɾ ɪ z ɛ m b ə l z j ɒː z \nPredicted: आइए आने वाले मॉड्यूल में इन विषयों पर विस्तार से बताने का प्रयास करते हैं\nReference: यह मौखिक निर्देश देना जारी रखें कि बिल्ली का चित्र कैसे बनाना है और उस बच्चे को पुरस्कृत करें जिसकी ड्राइंग आपकी काल्पनिक तस्वीर के ज़्यादा क़रीब हो\n------\nSource:  a n ɖ  f aj n ə ʎ i  ʋ iː s p oː k ə b aw ʈ  d̪ a ʈ ɪ z  ɹ eː z ɪ ŋ m ə ɹ ɑː l ɒ ʋ  a n ɪ n ɖ ɪ ʋ ɪ dʒ ə l \nPredicted: और अंत में, हमने इस बारे में बताया कि यह एक व्यक्ति के मनोबल को बढ़ा रहा है\nReference: और अंत में हमने यह भी कहा कि इससे व्यक्ति का मनोबल विकसित होता है\n------\nSource: d̪ ə  p ɾ aj ʋ ə ʈ p l eː s m ɛ n  p ɹ oː s ɛ s  ɪ z k ə m p ʎ iː ʈ ʎ i  ɖ ɪ f ə ɾ ə n f ɹ ə m iː  p ə b ʎ ɪ k  ɪ s j ʉː  a ʋ s ɪ c ʊ ɾ ə ʈʲ i dʒ  \nPredicted: निजी प्लेसमेंट प्रक्रिया प्रतिभूतियों के सार्वजनिक निर्गम से पूरी तरह से अलग होती है\nReference: निजी तौर पर शेयर आबंटन की प्रक्रिया प्रतिभूतियों के सार्वजनिक निर्गम से पूरी तरह से अलग है\n------\nSource:  d̪ eː ɑː  ɖ ə b ə l s p ɛ n ɖ ɪ ŋ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  m aj ɲ ɪ ŋ p ʉː l z  s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  ʋ a ʎ ɪ ɖ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  a n spn ʈ ɛ k n ɒ l ə dʒ i n ɛ ʈ ʋ ɜː k  t̪ ɹ ɛ ʈ s  ʋ ɪ l s iː ʋ ɒ n ɑː f ʈ ə ɾ d̪ iː ə d̪ ə ɾ \nPredicted: वे प्रतिभूति खतरे, ऋण, पॉल, सुरक्षा खतरे, भेद्यता खतरे और आईओटी तकनीक, नेटवर्क खतरे, हम एक के बाद एक देखेंगे\nReference: डबल स्पेंडिंग सिक्युरिटी थ्रेट, माइनिंग पूल सिक्युरिटी थ्रेट, वॉलट सिक्युरिटी थ्रेट, और ब्लॉकचैन प्रौद्योगिकी नेटवर्क खतरे\n------\nSource:  d̪ a ʈ  iː ʋ ə n  a  p ɜː s ə n  h ʉː s a ʈʲ ɪ s f aj z d̪ ə a k s ɛ s ɪ ŋ ɒ fʲ ɪ s ə ɾ \nPredicted: यह वो व्यक्ति है जो कार्यालय से बाहर पहुँच प्राप्त करता है\nReference: वह भी ऐसा व्यक्ति, जो आकलन अधिकारी, दस्तावेजी साक्ष्य, पहुंच भुगतान के कारणों को पूरा करता है\n------\n\n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}