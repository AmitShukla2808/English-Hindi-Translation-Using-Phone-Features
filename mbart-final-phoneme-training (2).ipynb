{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-05T19:13:06.996214Z",
     "iopub.status.busy": "2025-05-05T19:13:06.995557Z",
     "iopub.status.idle": "2025-05-05T19:13:43.699950Z",
     "shell.execute_reply": "2025-05-05T19:13:43.699075Z",
     "shell.execute_reply.started": "2025-05-05T19:13:06.996190Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:13:27.300072: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746472407.484629      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746472407.540057      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.16)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "/kaggle/input/ugce-phone-to-hindi/phone_20k_en2hi_translation.csv\n",
      "/kaggle/input/phone-data-text/phoneme_data.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "!pip install -q tokenizers datasets\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE, WordLevel\n",
    "from transformers import MBartTokenizerFast\n",
    "from tokenizers.trainers import BpeTrainer, WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "!pip install -q transformers datasets tokenizers huggingface_hub\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import re\n",
    "\n",
    "from transformers import (\n",
    "    EncoderDecoderModel, BertConfig, BertModel, PreTrainedTokenizerFast,\n",
    "    MBartForConditionalGeneration, TrainingArguments, Trainer, AutoModel\n",
    ")\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "!pip install evaluate\n",
    "import evaluate\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:13:47.396782Z",
     "iopub.status.busy": "2025-05-05T19:13:47.394968Z",
     "iopub.status.idle": "2025-05-05T19:13:47.732957Z",
     "shell.execute_reply": "2025-05-05T19:13:47.732154Z",
     "shell.execute_reply.started": "2025-05-05T19:13:47.396727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/ugce-phone-to-hindi/phone_20k_en2hi_translation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:13:47.854107Z",
     "iopub.status.busy": "2025-05-05T19:13:47.853444Z",
     "iopub.status.idle": "2025-05-05T19:13:47.873145Z",
     "shell.execute_reply": "2025-05-05T19:13:47.872361Z",
     "shell.execute_reply.started": "2025-05-05T19:13:47.854077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = data[['phones', 'hi_text']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:13:51.152749Z",
     "iopub.status.busy": "2025-05-05T19:13:51.152474Z",
     "iopub.status.idle": "2025-05-05T19:13:51.172225Z",
     "shell.execute_reply": "2025-05-05T19:13:51.171493Z",
     "shell.execute_reply.started": "2025-05-05T19:13:51.152726Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phones</th>\n",
       "      <th>hi_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ɖ ɪ ə s ʈʲ ʉː ɖ ə n s  ʋ ɛ l k ə m ʈ ʉː d̪ ə ...</td>\n",
       "      <td>प्रिय छात्रों, डिजिटल लाइब्रेरी पर पाठ्यक्रम क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d̪ ɪ s ʋ iː k  j ʉ l ɜː n ʈ ə b aw ʈ m eː dʒ ...</td>\n",
       "      <td>इस सप्ताह, आपने डिजिटल लाइब्रेरी में ई प्रिंट,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ɪ n  d̪ ə f ɜː s ʈ l ɛ s ə n ɖ ʊ ɾ ɪ n d̪ ə ʋ ...</td>\n",
       "      <td>सप्ताह के दौरान पहले पाठ में, आपको ग्रीनस्टोन ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ɪ n d̪ ə s ɛ k ə n l ɛ s ə n  ɖ ʊ ɾ ɪ ŋ d̪ ə ...</td>\n",
       "      <td>दूसरे अध्याय में, सप्ताह के दौरान, आपको डी स्प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j ʉ ʋ ɪ l ɒː l s oː bʲ iː spn n ɒ ʎ ɪ dʒ  ɒ n...</td>\n",
       "      <td>आपको डी स्पेस का उपयोग करके संग्रह निर्माण प्र...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18631</th>\n",
       "      <td>d̪ ə  cʷ ɛ ʃ tʃ ə n d̪ a ə ɹ aj z ɪ z ʋ ɛ ɹ i...</td>\n",
       "      <td>प्रश्न यह उठता है कि जब मैं एक तकनीकी विशेषज्ञ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18632</th>\n",
       "      <td>ɪ n d̪ a ʈ spn tʃ a p ʈ ə ɾ  ʋ ɒ ʈ ɛ ʋ ə a z ...</td>\n",
       "      <td>टीडीएस के अध्याय में, जो भी कहा गया है, उसे नि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18633</th>\n",
       "      <td>d̪ ə spn tʃ a p ʈ ə ɾ s eː z  d̪ a ʈ  ɪ f  aj ...</td>\n",
       "      <td>टीडीएस के अध्याय में बताया गया है कि, जब हमारी...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18634</th>\n",
       "      <td>f ɒː ɪ ɡ z aː m p ə l  aj p ʊ ʈ  s ɜː ʈ ə n m...</td>\n",
       "      <td>उदाहरण के लिए, मैंने बैंक के फिक्स्ड डिपॉजिट म...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18635</th>\n",
       "      <td>a n ɖ  ɒː l s oː  aj ɟ ɪ ʈ ə s ɜː ʈʲ ɪ fʲ ɪ c...</td>\n",
       "      <td>और मुझे एक प्रमाण पत्र भी मिलता है कर की राशि ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18636 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  phones  \\\n",
       "0       ɖ ɪ ə s ʈʲ ʉː ɖ ə n s  ʋ ɛ l k ə m ʈ ʉː d̪ ə ...   \n",
       "1       d̪ ɪ s ʋ iː k  j ʉ l ɜː n ʈ ə b aw ʈ m eː dʒ ...   \n",
       "2      ɪ n  d̪ ə f ɜː s ʈ l ɛ s ə n ɖ ʊ ɾ ɪ n d̪ ə ʋ ...   \n",
       "3       ɪ n d̪ ə s ɛ k ə n l ɛ s ə n  ɖ ʊ ɾ ɪ ŋ d̪ ə ...   \n",
       "4       j ʉ ʋ ɪ l ɒː l s oː bʲ iː spn n ɒ ʎ ɪ dʒ  ɒ n...   \n",
       "...                                                  ...   \n",
       "18631   d̪ ə  cʷ ɛ ʃ tʃ ə n d̪ a ə ɹ aj z ɪ z ʋ ɛ ɹ i...   \n",
       "18632   ɪ n d̪ a ʈ spn tʃ a p ʈ ə ɾ  ʋ ɒ ʈ ɛ ʋ ə a z ...   \n",
       "18633  d̪ ə spn tʃ a p ʈ ə ɾ s eː z  d̪ a ʈ  ɪ f  aj ...   \n",
       "18634   f ɒː ɪ ɡ z aː m p ə l  aj p ʊ ʈ  s ɜː ʈ ə n m...   \n",
       "18635   a n ɖ  ɒː l s oː  aj ɟ ɪ ʈ ə s ɜː ʈʲ ɪ fʲ ɪ c...   \n",
       "\n",
       "                                                 hi_text  \n",
       "0      प्रिय छात्रों, डिजिटल लाइब्रेरी पर पाठ्यक्रम क...  \n",
       "1      इस सप्ताह, आपने डिजिटल लाइब्रेरी में ई प्रिंट,...  \n",
       "2      सप्ताह के दौरान पहले पाठ में, आपको ग्रीनस्टोन ...  \n",
       "3      दूसरे अध्याय में, सप्ताह के दौरान, आपको डी स्प...  \n",
       "4      आपको डी स्पेस का उपयोग करके संग्रह निर्माण प्र...  \n",
       "...                                                  ...  \n",
       "18631  प्रश्न यह उठता है कि जब मैं एक तकनीकी विशेषज्ञ...  \n",
       "18632  टीडीएस के अध्याय में, जो भी कहा गया है, उसे नि...  \n",
       "18633  टीडीएस के अध्याय में बताया गया है कि, जब हमारी...  \n",
       "18634  उदाहरण के लिए, मैंने बैंक के फिक्स्ड डिपॉजिट म...  \n",
       "18635  और मुझे एक प्रमाण पत्र भी मिलता है कर की राशि ...  \n",
       "\n",
       "[18636 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:13:52.549429Z",
     "iopub.status.busy": "2025-05-05T19:13:52.548661Z",
     "iopub.status.idle": "2025-05-05T19:13:53.550435Z",
     "shell.execute_reply": "2025-05-05T19:13:53.549699Z",
     "shell.execute_reply.started": "2025-05-05T19:13:52.549402Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9f1192c7d043f48ee6b5b524de1dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18636 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.rename(columns={'phones': 'translation_en', 'hi_text': 'translation_hi'})\n",
    "\n",
    "# Convert to HuggingFace dataset\n",
    "dataset = Dataset.from_pandas(data)\n",
    "\n",
    "# Format as translation pair\n",
    "dataset = dataset.map(lambda x: {'translation': {'en': x['translation_en'], 'hi': x['translation_hi']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:14:07.664669Z",
     "iopub.status.busy": "2025-05-05T19:14:07.664078Z",
     "iopub.status.idle": "2025-05-05T19:14:13.843352Z",
     "shell.execute_reply": "2025-05-05T19:14:13.842579Z",
     "shell.execute_reply.started": "2025-05-05T19:14:07.664643Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f873ba25d354b578e2d5f43f2059126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a128b088bc454162bef53ff6fcf9f25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003b7ba3c80442518abb40d050b49450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b713cc61d9446adb1bd507e7cf831c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added 63 new phoneme tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('mbart-phoneme-tokenizer/tokenizer_config.json',\n",
       " 'mbart-phoneme-tokenizer/special_tokens_map.json',\n",
       " 'mbart-phoneme-tokenizer/sentencepiece.bpe.model',\n",
       " 'mbart-phoneme-tokenizer/added_tokens.json',\n",
       " 'mbart-phoneme-tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load original tokenizer\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "# 1. Load your dataset\n",
    "with open(\"/kaggle/input/phone-data-text/phoneme_data.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 2. Extract all unique tokens (assuming space-separated phonemes)\n",
    "phoneme_tokens = set()\n",
    "for line in lines:\n",
    "    tokens = re.findall(r'\\S+', line.strip())  # split on whitespace\n",
    "    phoneme_tokens.update(tokens)\n",
    "\n",
    "phoneme_tokens = list(phoneme_tokens)\n",
    "\n",
    "# 3. Add to tokenizer\n",
    "num_added = tokenizer.add_tokens(phoneme_tokens)\n",
    "print(f\"✅ Added {num_added} new phoneme tokens\")\n",
    "\n",
    "# 4. Save tokenizer\n",
    "tokenizer.save_pretrained(\"mbart-phoneme-tokenizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:14:13.844533Z",
     "iopub.status.busy": "2025-05-05T19:14:13.844329Z",
     "iopub.status.idle": "2025-05-05T19:14:30.309380Z",
     "shell.execute_reply": "2025-05-05T19:14:30.308506Z",
     "shell.execute_reply.started": "2025-05-05T19:14:13.844517Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f744c568f54040e1ac3f07302fae9567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be33b838eab49d79642d960b6d32cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MBartScaledWordEmbedding(250080, 1024, padding_idx=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"/kaggle/working/mbart-phoneme-tokenizer\")\n",
    "\n",
    "# Load model\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer.add_tokens([\"<phoneme>\"])\n",
    "# Resize embeddings\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:14:33.679583Z",
     "iopub.status.busy": "2025-05-05T19:14:33.679291Z",
     "iopub.status.idle": "2025-05-05T19:14:33.685373Z",
     "shell.execute_reply": "2025-05-05T19:14:33.684798Z",
     "shell.execute_reply.started": "2025-05-05T19:14:33.679554Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBartForConditionalGeneration(\n",
      "  (model): MBartModel(\n",
      "    (shared): MBartScaledWordEmbedding(250080, 1024, padding_idx=1)\n",
      "    (encoder): MBartEncoder(\n",
      "      (embed_tokens): MBartScaledWordEmbedding(250080, 1024, padding_idx=1)\n",
      "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x MBartEncoderLayer(\n",
      "          (self_attn): MBartSdpaAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): MBartDecoder(\n",
      "      (embed_tokens): MBartScaledWordEmbedding(250080, 1024, padding_idx=1)\n",
      "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x MBartDecoderLayer(\n",
      "          (self_attn): MBartSdpaAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartSdpaAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=250080, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:14:38.178229Z",
     "iopub.status.busy": "2025-05-05T19:14:38.177627Z",
     "iopub.status.idle": "2025-05-05T19:14:38.181938Z",
     "shell.execute_reply": "2025-05-05T19:14:38.181098Z",
     "shell.execute_reply.started": "2025-05-05T19:14:38.178200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer.src_lang = \"en_XX\"\n",
    "tokenizer.tgt_lang = \"hi_IN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:14:49.568935Z",
     "iopub.status.busy": "2025-05-05T19:14:49.568586Z",
     "iopub.status.idle": "2025-05-05T19:14:54.784984Z",
     "shell.execute_reply": "2025-05-05T19:14:54.784292Z",
     "shell.execute_reply.started": "2025-05-05T19:14:49.568913Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b2d2d6f5b04de3acda4455746ad613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18636 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Iterate over the list of dictionaries for the \"translation\" column\n",
    "    inputs = [\"<phoneme> \" + trans[\"en\"] for trans in examples[\"translation\"]]\n",
    "    targets = [trans[\"hi\"] for trans in examples[\"translation\"]]\n",
    "    \n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    # Tokenize the targets in the target context\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:15:16.035900Z",
     "iopub.status.busy": "2025-05-05T19:15:16.035386Z",
     "iopub.status.idle": "2025-05-05T19:15:16.040494Z",
     "shell.execute_reply": "2025-05-05T19:15:16.039791Z",
     "shell.execute_reply.started": "2025-05-05T19:15:16.035873Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation_en', 'translation_hi', 'translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 18636\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:15:17.616199Z",
     "iopub.status.busy": "2025-05-05T19:15:17.615649Z",
     "iopub.status.idle": "2025-05-05T19:15:25.556426Z",
     "shell.execute_reply": "2025-05-05T19:15:25.555711Z",
     "shell.execute_reply.started": "2025-05-05T19:15:17.616176Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamushuk890\u001b[0m (\u001b[33mamushuk890-iiit-hyderabad\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"a99e291f456a7abc8c5633970e998e968c1ef8b2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:15:31.535867Z",
     "iopub.status.busy": "2025-05-05T19:15:31.534742Z",
     "iopub.status.idle": "2025-05-05T19:15:34.476083Z",
     "shell.execute_reply": "2025-05-05T19:15:34.475523Z",
     "shell.execute_reply.started": "2025-05-05T19:15:31.535843Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a3cf4197504a9a9f2f8ac96f6d3080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7562520617464e5d9a2f980349824855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e77256e90e84d7cad9871bef2fe3f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 16772\n",
      "Test (Eval) dataset size: 1864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/3619160158.py:110: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "\n",
    "    # Decode the predictions and labels\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Prepare references as a list of lists\n",
    "    references = [[label] for label in decoded_labels]\n",
    "\n",
    "    # Compute BLEU score\n",
    "    result = bleu_metric.compute(predictions=decoded_preds, references=references)\n",
    "\n",
    "    # Return the BLEU score\n",
    "    return {\"bleu\": result[\"bleu\"]}\n",
    "\n",
    "\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test (Eval) dataset size: {len(eval_dataset)}\")\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mbart50-hi\",\n",
    "    eval_strategy=\"epoch\",         # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",         # Save a checkpoint at the end of each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,            # Keep only the most recent checkpoint\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "import random\n",
    "\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "class InferenceCallback(TrainerCallback):\n",
    "    def __init__(self, tokenizer, model, eval_dataset, num_samples=10, output_file=\"inference_samples.csv\"):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.num_samples = num_samples\n",
    "        self.output_file = output_file\n",
    "        self.sample_indices = random.sample(range(len(self.eval_dataset)), self.num_samples)\n",
    "        self.sample_texts = [self.eval_dataset[i]['translation']['en'] for i in self.sample_indices]\n",
    "        self.references = [self.eval_dataset[i]['translation']['hi'] for i in self.sample_indices]\n",
    "        self.outputs = []\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        # Prepare inputs\n",
    "        inputs = self.tokenizer(self.sample_texts, padding=True, truncation=True, return_tensors=\"pt\").to(self.model.device)\n",
    "        generated_ids = self.model.generate(**inputs, max_length=128, num_beams=4, early_stopping=True)\n",
    "        predictions = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "        # Save this epoch's outputs for final CSV\n",
    "        for src, ref, pred in zip(self.sample_texts, self.references, predictions):\n",
    "            self.outputs.append({\n",
    "                \"epoch\": state.epoch,\n",
    "                \"source\": src,\n",
    "                \"reference\": ref,\n",
    "                \"prediction\": pred\n",
    "            })\n",
    "\n",
    "        # Console output\n",
    "        print(f\"\\n--- Inference After Epoch {state.epoch:.1f} ---\")\n",
    "        for src, pred, ref in zip(self.sample_texts, predictions, self.references):\n",
    "            print(f\"Source: {src}\")\n",
    "            print(f\"Predicted: {pred}\")\n",
    "            print(f\"Reference: {ref}\")\n",
    "            print(\"------\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        return control\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        # Write all accumulated outputs to CSV at the end of training\n",
    "        keys = [\"epoch\", \"source\", \"reference\", \"prediction\"]\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_csv = f\"inference_samples_{timestamp}.csv\"\n",
    "\n",
    "        with open(output_csv, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=keys)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(self.outputs)\n",
    "\n",
    "        print(f\"Inference samples saved to {output_csv}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the custom inference callback\n",
    "inference_callback = InferenceCallback(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    eval_dataset=eval_dataset,\n",
    "    num_samples=10  # You can adjust this to 3 or 4 samples\n",
    ")\n",
    "\n",
    "# Create the trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,  # Using the separate test set (1% of original data)\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[inference_callback]  # Add the inference callback here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:15:45.219494Z",
     "iopub.status.busy": "2025-05-05T19:15:45.219012Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250505_191545-snuiapxz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amushuk890-iiit-hyderabad/huggingface/runs/snuiapxz' target=\"_blank\">./mbart50-hi</a></strong> to <a href='https://wandb.ai/amushuk890-iiit-hyderabad/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/amushuk890-iiit-hyderabad/huggingface' target=\"_blank\">https://wandb.ai/amushuk890-iiit-hyderabad/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/amushuk890-iiit-hyderabad/huggingface/runs/snuiapxz' target=\"_blank\">https://wandb.ai/amushuk890-iiit-hyderabad/huggingface/runs/snuiapxz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17505' max='41930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17505/41930 3:27:37 < 4:49:44, 1.40 it/s, Epoch 4.17/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.575300</td>\n",
       "      <td>0.567709</td>\n",
       "      <td>0.173871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.474100</td>\n",
       "      <td>0.506063</td>\n",
       "      <td>0.216904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.385200</td>\n",
       "      <td>0.493454</td>\n",
       "      <td>0.234507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.497158</td>\n",
       "      <td>0.236765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inference After Epoch 1.0 ---\n",
      "Source:  p ə ʈʲ ɪ n a s ʈ ɾ a ʈ ə dʒ i ɪ n p l eː s d̪ a ʈ ɲ iː ɖ z  ʈ ʉː bʲ iː  f ɒ l oː ɖ ɪ n d̪ iː ɪ ʋ ɛ n ʈ  ɒ ʋ  ɛ ɲ i ɒ ʋ d̪ ə  fʲ ʉː tʃ ə  t̪ ɹ ɛ ʈ s  ʈ ʉː d̪ ə n ɛ ʈ ʋ ɜː k  ɪ n  ə d̪ ə ʋ ɜː ɖ z  spn  m ɛ ʃ ə z  \n",
      "Predicted: ट्रैटेजिस इंस्पेस के रूप में, नेटवर्क में किसी भी प्रकार की साइबर क्राइम्स के इवेंट में शामिल होने की आवश्यकता है\n",
      "Reference: भविष्य में किसी भी तरह के नेटवर्क के खतरों के लिए दूसरे शब्दों में, सक्रिय उपायों को लागू करने की आवश्यकता के लिए एक रणनीति बनाना\n",
      "------\n",
      "Source: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i s ɜː ʋ ɪ s ɪ z  ʃ ʊ ɖ ɪ n ʃ ʊ ə d̪ a ʈ j ʉː z ə z dʒ ə s ʈ p ɹ ə ʋ aj ɖ ɪ ŋ spn  b ɛ ɲ ɪ fʲ ɪ ʈ f ɹ ə m b ɛ ʈ ə ɾ  ɾ ɛ k ə m ə n ɖ eː ʃ ə n z  a n ɖ  s ɜː tʃ  ɾ ɪ z ə l ʈ s \n",
      "Predicted: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ताओं को डिजिटल लाइब्रेरी के माध्यम से डिजिटल लाइब्रेरी और सर्च रिज़ॉल्यूशन प्रदान किया जाता है\n",
      "Reference: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ता केवल एनोटेशन प्रदान करें, बेहतर रिकमेंडेशंस ( और खोज परिणामों से लाभान्वित हों\n",
      "------\n",
      "Source:  d̪ ə p ɒ pʲ ʊ l a ɾ ɪ ʈʲ i  ɒ ʋ d̪ ə ʋ ɜː ɖ  ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  k a n bʲ iː ʈ ɾ eː s ʈ  ʈ ʉː d̪ ə ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  ɪ ɲ ɪ ʃ ə ʈʲ ɪ ʋ z  \n",
      "Predicted: डिजिटल लाइब्रेरी की दुनिया की लोकप्रियता डिजिटल लाइब्रेरी उपक्रमों से संबंधित हो सकती है\n",
      "Reference: डिजिटल लाइब्रेरी शब्द की लोकप्रियता का पता डिजिटल लाइब्रेरी पहल से लगाया जा सकता है\n",
      "------\n",
      "Source: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɹ i z ʃ ʊ ɖ ɒː l s oː p ɹ ə ʋ aj ɖ ɾ ɛ k ə m ə n ɖ eː ʃ ə n z s ɜː ʋ ɪ s ɪ z  f ə ɪ ɡ z aː m p ə l  b eː s ʈ  ɑ n d̪ ə  k a n ʈ ɛ k s  a n ɖ ɾ ɪ s ɒː s ɪ z  spn  ɑː b eː s ʈ ɒ n k ə l a b ə ɾ eː ʈʲ ɪ ʋ fʲ ɪ l ʈ ə ɾ ɪ n  \n",
      "Predicted: सिमेंटिक डिजिटल लाइब्रेरी को कंटेक्स्ट और संसाधन के आधार पर डिजिटल ऑब्जेक्ट पर आधारित रिक्वेंशन सेवाएं भी प्रदान करनी चाहिए\n",
      "Reference: सिमेंटिक डिजिटल लाइब्रेरी को भी रिकमेंडेशंस सेवाएं प्रदान करनी चाहिए, उदाहरण के लिए, संदर्भ और संसाधनों के आधार पर एनोटेशन कोलाबोरेटिव फ़िल्टरिंग पर आधारित हैं\n",
      "------\n",
      "Source:  m ʉː ʋ ɪ ŋ ɒ n  a s ʋ iː a ʋ s iː n d̪ a ʈ ɪ n d̪ ə p ɹ ə m oː ʃ ə n a k ʈʲ ɪ ʋ ɪ ʈʲ i z  d̪ a ʈ  d̪ iː  p ɹ ə m oː ʈ ə z ɑː ʋ ɛ ɾ i ɪ m p ɒː ʈ ə n ʈ  p ɜː s ə n z  ɪ n d̪ ə k ɒː p ə ɹ ə ʈ ə f ɛː z ɒ ʋ d̪ ə k ə m p ə ɲ i  s oː d̪ eː a ʋ ə ʋ ɛ ɹ i  b ɛ ʈ ə ɾ k ə n ʈ ɹ oː l oː ʋ ə d̪ ə m a ɲ ɪ dʒ m ɛ n ʈ ɒ ʋ d̪ ə k ə m p ə ɲ i  a n d̪ eː c iː p d̪ ɪ s k ə n ʈ ɾ oː l  t̪ ɹ ʉː aw  d̪ ə l aj f ɒ ʋ d̪ iː  k ə m p ə ɲ i  a n ɖ  d̪ iː p ɹ ə m oː ʈ ə z  aː  ɒː l s oː  d̪ iː p ɜː s ə n z  h ʉː  a k ʈ ʉ ə ʎ i s ɪ ŋ k  a n ɖ  s ʋ ɪ m  ʋ ɪ d̪ d̪ ə  k ɒː p ə ɾ ə ʈ  l aj f \n",
      "Predicted: जैसा कि हमने देखा है कि प्रमोटरों में कंपनी के जीवन के साथ साथ प्रमोटरों में भी बहुत महत्वपूर्ण व्यक्ति होते हैं, इसलिए कंपनी के प्रमोटरों में एक बहुत ही महत्वपूर्ण नियंत्रण होता है\n",
      "Reference: आगे बढ़ते हुए, जैसा कि हमने देखा है कि प्रमोशन गतिविधियों के दौरान कंपनी के कॉर्पोरेट अफेयर्स में प्रमोटर बहुत महत्वपूर्ण होते हैं, इसलिए कंपनी के प्रबंधन पर उनका काफी नियंत्रण होता है तथा इस तरह वे जीवन भर कंपनी पर नियंत्रण बनाए रखते हैं और प्रमोटर ऐसे व्यक्ति भी होते हैं जो वास्तव में कॉर्पोरेट जीवन के साथ उतार चढ़ाव का अनुभव करते हैं\n",
      "------\n",
      "Source:  k ə n ʈʲ ɪ ɲ ʉː ʈ ə ɟ ɪ ʋ ʋ ɜː b ə l ɪ n s ʈ ɹ ə c ʃ ə n z  ɒ n h aw ʈ ə ɖ ɹ ɒː d̪ ə k a ʈ  a n ə ʋ ɒː ɖ d̪ ə tʃ aj l ɖ  h ʉː z ɖ ɹ ɒ ʋ ɪ ŋ  k l oː s ʎ iː ɾ ɪ z ɛ m b ə l z j ɒː z \n",
      "Predicted: साइबर अपराध के जूरिडिक्शन का वर्णन कर पाएंगे\n",
      "Reference: यह मौखिक निर्देश देना जारी रखें कि बिल्ली का चित्र कैसे बनाना है और उस बच्चे को पुरस्कृत करें जिसकी ड्राइंग आपकी काल्पनिक तस्वीर के ज़्यादा क़रीब हो\n",
      "------\n",
      "Source:  a n ɖ  f aj n ə ʎ i  ʋ iː s p oː k ə b aw ʈ  d̪ a ʈ ɪ z  ɹ eː z ɪ ŋ m ə ɹ ɑː l ɒ ʋ  a n ɪ n ɖ ɪ ʋ ɪ dʒ ə l \n",
      "Predicted: और अंत में, हम इस बारे में बात करते हैं कि वह एक व्यक्ति की मर्जरल है\n",
      "Reference: और अंत में हमने यह भी कहा कि इससे व्यक्ति का मनोबल विकसित होता है\n",
      "------\n",
      "Source: d̪ ə  p ɾ aj ʋ ə ʈ p l eː s m ɛ n  p ɹ oː s ɛ s  ɪ z k ə m p ʎ iː ʈ ʎ i  ɖ ɪ f ə ɾ ə n f ɹ ə m iː  p ə b ʎ ɪ k  ɪ s j ʉː  a ʋ s ɪ c ʊ ɾ ə ʈʲ i dʒ  \n",
      "Predicted: प्राइवेट प्लेसमेंट प्रॉसेस आमतौर पर सार्वजनिक निर्गम और सुरक्षा से भिन्न होते हैं\n",
      "Reference: निजी तौर पर शेयर आबंटन की प्रक्रिया प्रतिभूतियों के सार्वजनिक निर्गम से पूरी तरह से अलग है\n",
      "------\n",
      "Source:  d̪ eː ɑː  ɖ ə b ə l s p ɛ n ɖ ɪ ŋ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  m aj ɲ ɪ ŋ p ʉː l z  s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  ʋ a ʎ ɪ ɖ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  a n spn ʈ ɛ k n ɒ l ə dʒ i n ɛ ʈ ʋ ɜː k  t̪ ɹ ɛ ʈ s  ʋ ɪ l s iː ʋ ɒ n ɑː f ʈ ə ɾ d̪ iː ə d̪ ə ɾ \n",
      "Predicted: वे सुरक्षा खतरों को कम करने में सक्षम होते हैं, जैसे कि सुरक्षा खतरों को कम करने में, सुरक्षा खतरों को कम करने में, नेटवर्क खतरों को कम करने में, नेटवर्क खतरों को कम करने में, नेटवर्क खतरों को कम करने में और नेटवर्क खतरों को कम करने में मदद करते हैं\n",
      "Reference: डबल स्पेंडिंग सिक्युरिटी थ्रेट, माइनिंग पूल सिक्युरिटी थ्रेट, वॉलट सिक्युरिटी थ्रेट, और ब्लॉकचैन प्रौद्योगिकी नेटवर्क खतरे\n",
      "------\n",
      "Source:  d̪ a ʈ  iː ʋ ə n  a  p ɜː s ə n  h ʉː s a ʈʲ ɪ s f aj z d̪ ə a k s ɛ s ɪ ŋ ɒ fʲ ɪ s ə ɾ \n",
      "Predicted: यह एक व्यक्ति है जो अभिलेखागार को एक्सेस करने में मदद करता है\n",
      "Reference: वह भी ऐसा व्यक्ति, जो आकलन अधिकारी, दस्तावेजी साक्ष्य, पहुंच भुगतान के कारणों को पूरा करता है\n",
      "------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inference After Epoch 2.0 ---\n",
      "Source:  p ə ʈʲ ɪ n a s ʈ ɾ a ʈ ə dʒ i ɪ n p l eː s d̪ a ʈ ɲ iː ɖ z  ʈ ʉː bʲ iː  f ɒ l oː ɖ ɪ n d̪ iː ɪ ʋ ɛ n ʈ  ɒ ʋ  ɛ ɲ i ɒ ʋ d̪ ə  fʲ ʉː tʃ ə  t̪ ɹ ɛ ʈ s  ʈ ʉː d̪ ə n ɛ ʈ ʋ ɜː k  ɪ n  ə d̪ ə ʋ ɜː ɖ z  spn  m ɛ ʃ ə z  \n",
      "Predicted: ट्रैफ़िक के स्थान के रूप में, नेटवर्क में किसी भी प्रकार के भविष्य के खतरों का पता लगाने की आवश्यकता है\n",
      "Reference: भविष्य में किसी भी तरह के नेटवर्क के खतरों के लिए दूसरे शब्दों में, सक्रिय उपायों को लागू करने की आवश्यकता के लिए एक रणनीति बनाना\n",
      "------\n",
      "Source: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i s ɜː ʋ ɪ s ɪ z  ʃ ʊ ɖ ɪ n ʃ ʊ ə d̪ a ʈ j ʉː z ə z dʒ ə s ʈ p ɹ ə ʋ aj ɖ ɪ ŋ spn  b ɛ ɲ ɪ fʲ ɪ ʈ f ɹ ə m b ɛ ʈ ə ɾ  ɾ ɛ k ə m ə n ɖ eː ʃ ə n z  a n ɖ  s ɜː tʃ  ɾ ɪ z ə l ʈ s \n",
      "Predicted: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करने के लिए कि उपयोगकर्ता बेहतर संसाधनों और सर्च परिणामों से बेहतर लाभ प्रदान करते हैं\n",
      "Reference: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ता केवल एनोटेशन प्रदान करें, बेहतर रिकमेंडेशंस ( और खोज परिणामों से लाभान्वित हों\n",
      "------\n",
      "Source:  d̪ ə p ɒ pʲ ʊ l a ɾ ɪ ʈʲ i  ɒ ʋ d̪ ə ʋ ɜː ɖ  ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  k a n bʲ iː ʈ ɾ eː s ʈ  ʈ ʉː d̪ ə ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  ɪ ɲ ɪ ʃ ə ʈʲ ɪ ʋ z  \n",
      "Predicted: डिजिटल लाइब्रेरी की लोकप्रियता डिजिटल लाइब्रेरी पहलों से संबंधित हो सकती है\n",
      "Reference: डिजिटल लाइब्रेरी शब्द की लोकप्रियता का पता डिजिटल लाइब्रेरी पहल से लगाया जा सकता है\n",
      "------\n",
      "Source: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɹ i z ʃ ʊ ɖ ɒː l s oː p ɹ ə ʋ aj ɖ ɾ ɛ k ə m ə n ɖ eː ʃ ə n z s ɜː ʋ ɪ s ɪ z  f ə ɪ ɡ z aː m p ə l  b eː s ʈ  ɑ n d̪ ə  k a n ʈ ɛ k s  a n ɖ ɾ ɪ s ɒː s ɪ z  spn  ɑː b eː s ʈ ɒ n k ə l a b ə ɾ eː ʈʲ ɪ ʋ fʲ ɪ l ʈ ə ɾ ɪ n  \n",
      "Predicted: सिमेंटिक डिजिटल लाइब्रेरी को टेक्स्ट और संसाधनों के आधार पर एक सहयोगी फ़िल्टरिंग के आधार पर सिमेंटिक डिजिटल लाइब्रेरी सेवाएं भी प्रदान करनी चाहिए\n",
      "Reference: सिमेंटिक डिजिटल लाइब्रेरी को भी रिकमेंडेशंस सेवाएं प्रदान करनी चाहिए, उदाहरण के लिए, संदर्भ और संसाधनों के आधार पर एनोटेशन कोलाबोरेटिव फ़िल्टरिंग पर आधारित हैं\n",
      "------\n",
      "Source:  m ʉː ʋ ɪ ŋ ɒ n  a s ʋ iː a ʋ s iː n d̪ a ʈ ɪ n d̪ ə p ɹ ə m oː ʃ ə n a k ʈʲ ɪ ʋ ɪ ʈʲ i z  d̪ a ʈ  d̪ iː  p ɹ ə m oː ʈ ə z ɑː ʋ ɛ ɾ i ɪ m p ɒː ʈ ə n ʈ  p ɜː s ə n z  ɪ n d̪ ə k ɒː p ə ɹ ə ʈ ə f ɛː z ɒ ʋ d̪ ə k ə m p ə ɲ i  s oː d̪ eː a ʋ ə ʋ ɛ ɹ i  b ɛ ʈ ə ɾ k ə n ʈ ɹ oː l oː ʋ ə d̪ ə m a ɲ ɪ dʒ m ɛ n ʈ ɒ ʋ d̪ ə k ə m p ə ɲ i  a n d̪ eː c iː p d̪ ɪ s k ə n ʈ ɾ oː l  t̪ ɹ ʉː aw  d̪ ə l aj f ɒ ʋ d̪ iː  k ə m p ə ɲ i  a n ɖ  d̪ iː p ɹ ə m oː ʈ ə z  aː  ɒː l s oː  d̪ iː p ɜː s ə n z  h ʉː  a k ʈ ʉ ə ʎ i s ɪ ŋ k  a n ɖ  s ʋ ɪ m  ʋ ɪ d̪ d̪ ə  k ɒː p ə ɾ ə ʈ  l aj f \n",
      "Predicted: जैसा कि हमने देखा कि प्रमोशन गतिविधियों में प्रमोटर बहुत महत्वपूर्ण होते हैं और प्रमोटर कंपनी के प्रमोटर्स के जीवन को आगे बढ़ाते हैं और साथ ही प्रमोटर्स को प्रमोटर्स के जीवन को आगे बढ़ाने के लिए प्रमोटर्स को प्रोत्साहित करते हैं और प्रमोटर्स के जीवन को आगे बढ़ाने के लिए प्रमोटर्स को प्रोत्साहित करते हैं\n",
      "Reference: आगे बढ़ते हुए, जैसा कि हमने देखा है कि प्रमोशन गतिविधियों के दौरान कंपनी के कॉर्पोरेट अफेयर्स में प्रमोटर बहुत महत्वपूर्ण होते हैं, इसलिए कंपनी के प्रबंधन पर उनका काफी नियंत्रण होता है तथा इस तरह वे जीवन भर कंपनी पर नियंत्रण बनाए रखते हैं और प्रमोटर ऐसे व्यक्ति भी होते हैं जो वास्तव में कॉर्पोरेट जीवन के साथ उतार चढ़ाव का अनुभव करते हैं\n",
      "------\n",
      "Source:  k ə n ʈʲ ɪ ɲ ʉː ʈ ə ɟ ɪ ʋ ʋ ɜː b ə l ɪ n s ʈ ɹ ə c ʃ ə n z  ɒ n h aw ʈ ə ɖ ɹ ɒː d̪ ə k a ʈ  a n ə ʋ ɒː ɖ d̪ ə tʃ aj l ɖ  h ʉː z ɖ ɹ ɒ ʋ ɪ ŋ  k l oː s ʎ iː ɾ ɪ z ɛ m b ə l z j ɒː z \n",
      "Predicted: कैट को कैसे हटाने के बारे में निरंतर विद्वत्तापूर्ण निर्देशों का पालन करें और चुनौतियों को हल करें, जिनका सामना आप कर रहे हैं\n",
      "Reference: यह मौखिक निर्देश देना जारी रखें कि बिल्ली का चित्र कैसे बनाना है और उस बच्चे को पुरस्कृत करें जिसकी ड्राइंग आपकी काल्पनिक तस्वीर के ज़्यादा क़रीब हो\n",
      "------\n",
      "Source:  a n ɖ  f aj n ə ʎ i  ʋ iː s p oː k ə b aw ʈ  d̪ a ʈ ɪ z  ɹ eː z ɪ ŋ m ə ɹ ɑː l ɒ ʋ  a n ɪ n ɖ ɪ ʋ ɪ dʒ ə l \n",
      "Predicted: और अंत में, हम इस बारे में बात करते हैं कि यह एक व्यक्ति की मृत्यु से संबंधित है\n",
      "Reference: और अंत में हमने यह भी कहा कि इससे व्यक्ति का मनोबल विकसित होता है\n",
      "------\n",
      "Source: d̪ ə  p ɾ aj ʋ ə ʈ p l eː s m ɛ n  p ɹ oː s ɛ s  ɪ z k ə m p ʎ iː ʈ ʎ i  ɖ ɪ f ə ɾ ə n f ɹ ə m iː  p ə b ʎ ɪ k  ɪ s j ʉː  a ʋ s ɪ c ʊ ɾ ə ʈʲ i dʒ  \n",
      "Predicted: निजी प्लेसमेंट प्रक्रिया पूरी तरह से प्रतिभूतियों के सार्वजनिक निर्गम से अलग है\n",
      "Reference: निजी तौर पर शेयर आबंटन की प्रक्रिया प्रतिभूतियों के सार्वजनिक निर्गम से पूरी तरह से अलग है\n",
      "------\n",
      "Source:  d̪ eː ɑː  ɖ ə b ə l s p ɛ n ɖ ɪ ŋ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  m aj ɲ ɪ ŋ p ʉː l z  s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  ʋ a ʎ ɪ ɖ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  a n spn ʈ ɛ k n ɒ l ə dʒ i n ɛ ʈ ʋ ɜː k  t̪ ɹ ɛ ʈ s  ʋ ɪ l s iː ʋ ɒ n ɑː f ʈ ə ɾ d̪ iː ə d̪ ə ɾ \n",
      "Predicted: वे वल्नेरेबिलिटी खतरे, सुरक्षा खतरे, वल्नेरेबिलिटी खतरे और अरक्षितता खतरे हैं\n",
      "Reference: डबल स्पेंडिंग सिक्युरिटी थ्रेट, माइनिंग पूल सिक्युरिटी थ्रेट, वॉलट सिक्युरिटी थ्रेट, और ब्लॉकचैन प्रौद्योगिकी नेटवर्क खतरे\n",
      "------\n",
      "Source:  d̪ a ʈ  iː ʋ ə n  a  p ɜː s ə n  h ʉː s a ʈʲ ɪ s f aj z d̪ ə a k s ɛ s ɪ ŋ ɒ fʲ ɪ s ə ɾ \n",
      "Predicted: यह वह व्यक्ति है जो अधिकारी को एक्सेस करने का अधिकार प्राप्त करता है\n",
      "Reference: वह भी ऐसा व्यक्ति, जो आकलन अधिकारी, दस्तावेजी साक्ष्य, पहुंच भुगतान के कारणों को पूरा करता है\n",
      "------\n",
      "\n",
      "\n",
      "\n",
      "--- Inference After Epoch 3.0 ---\n",
      "Source:  p ə ʈʲ ɪ n a s ʈ ɾ a ʈ ə dʒ i ɪ n p l eː s d̪ a ʈ ɲ iː ɖ z  ʈ ʉː bʲ iː  f ɒ l oː ɖ ɪ n d̪ iː ɪ ʋ ɛ n ʈ  ɒ ʋ  ɛ ɲ i ɒ ʋ d̪ ə  fʲ ʉː tʃ ə  t̪ ɹ ɛ ʈ s  ʈ ʉː d̪ ə n ɛ ʈ ʋ ɜː k  ɪ n  ə d̪ ə ʋ ɜː ɖ z  spn  m ɛ ʃ ə z  \n",
      "Predicted: ट्रैजिस के रूप में प्लेस में जो कि किसी भी प्रकार के खतरों से नेटवर्क में अन्य खतरों के उपायों में शामिल होने की आवश्यकता है\n",
      "Reference: भविष्य में किसी भी तरह के नेटवर्क के खतरों के लिए दूसरे शब्दों में, सक्रिय उपायों को लागू करने की आवश्यकता के लिए एक रणनीति बनाना\n",
      "------\n",
      "Source: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i s ɜː ʋ ɪ s ɪ z  ʃ ʊ ɖ ɪ n ʃ ʊ ə d̪ a ʈ j ʉː z ə z dʒ ə s ʈ p ɹ ə ʋ aj ɖ ɪ ŋ spn  b ɛ ɲ ɪ fʲ ɪ ʈ f ɹ ə m b ɛ ʈ ə ɾ  ɾ ɛ k ə m ə n ɖ eː ʃ ə n z  a n ɖ  s ɜː tʃ  ɾ ɪ z ə l ʈ s \n",
      "Predicted: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ता बेहतर व्यवस्थाओं और सर्च परिणामों से बेहतर लाभ प्रदान करते हैं\n",
      "Reference: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ता केवल एनोटेशन प्रदान करें, बेहतर रिकमेंडेशंस ( और खोज परिणामों से लाभान्वित हों\n",
      "------\n",
      "Source:  d̪ ə p ɒ pʲ ʊ l a ɾ ɪ ʈʲ i  ɒ ʋ d̪ ə ʋ ɜː ɖ  ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  k a n bʲ iː ʈ ɾ eː s ʈ  ʈ ʉː d̪ ə ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  ɪ ɲ ɪ ʃ ə ʈʲ ɪ ʋ z  \n",
      "Predicted: शब्द डिजिटल लाइब्रेरी की लोकप्रियता डिजिटल लाइब्रेरी पहलों से जुड़ी हो सकती है\n",
      "Reference: डिजिटल लाइब्रेरी शब्द की लोकप्रियता का पता डिजिटल लाइब्रेरी पहल से लगाया जा सकता है\n",
      "------\n",
      "Source: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɹ i z ʃ ʊ ɖ ɒː l s oː p ɹ ə ʋ aj ɖ ɾ ɛ k ə m ə n ɖ eː ʃ ə n z s ɜː ʋ ɪ s ɪ z  f ə ɪ ɡ z aː m p ə l  b eː s ʈ  ɑ n d̪ ə  k a n ʈ ɛ k s  a n ɖ ɾ ɪ s ɒː s ɪ z  spn  ɑː b eː s ʈ ɒ n k ə l a b ə ɾ eː ʈʲ ɪ ʋ fʲ ɪ l ʈ ə ɾ ɪ n  \n",
      "Predicted: सिमेंटिक डिजिटल लाइब्रेरी को सामग्री और संसाधनों को संरचित फ़िल्टरिंग पर आधारित रिकॉर्डिंग सेवाएं भी प्रदान करनी चाहिए\n",
      "Reference: सिमेंटिक डिजिटल लाइब्रेरी को भी रिकमेंडेशंस सेवाएं प्रदान करनी चाहिए, उदाहरण के लिए, संदर्भ और संसाधनों के आधार पर एनोटेशन कोलाबोरेटिव फ़िल्टरिंग पर आधारित हैं\n",
      "------\n",
      "Source:  m ʉː ʋ ɪ ŋ ɒ n  a s ʋ iː a ʋ s iː n d̪ a ʈ ɪ n d̪ ə p ɹ ə m oː ʃ ə n a k ʈʲ ɪ ʋ ɪ ʈʲ i z  d̪ a ʈ  d̪ iː  p ɹ ə m oː ʈ ə z ɑː ʋ ɛ ɾ i ɪ m p ɒː ʈ ə n ʈ  p ɜː s ə n z  ɪ n d̪ ə k ɒː p ə ɹ ə ʈ ə f ɛː z ɒ ʋ d̪ ə k ə m p ə ɲ i  s oː d̪ eː a ʋ ə ʋ ɛ ɹ i  b ɛ ʈ ə ɾ k ə n ʈ ɹ oː l oː ʋ ə d̪ ə m a ɲ ɪ dʒ m ɛ n ʈ ɒ ʋ d̪ ə k ə m p ə ɲ i  a n d̪ eː c iː p d̪ ɪ s k ə n ʈ ɾ oː l  t̪ ɹ ʉː aw  d̪ ə l aj f ɒ ʋ d̪ iː  k ə m p ə ɲ i  a n ɖ  d̪ iː p ɹ ə m oː ʈ ə z  aː  ɒː l s oː  d̪ iː p ɜː s ə n z  h ʉː  a k ʈ ʉ ə ʎ i s ɪ ŋ k  a n ɖ  s ʋ ɪ m  ʋ ɪ d̪ d̪ ə  k ɒː p ə ɾ ə ʈ  l aj f \n",
      "Predicted: जैसे कि हमने देखा है कि कंपनी के प्रमोशन गतिविधियों में यह नियंत्रित होता है कि कंपनी के प्रमोटर बहुत महत्वपूर्ण होते हैं और कॉर्पोरेट मामलों के प्रमोशन के साथ साथ उन लोगों को भी नियंत्रित किया जाता है जो कॉर्पोरेट जीवन को नियंत्रित करते हैं\n",
      "Reference: आगे बढ़ते हुए, जैसा कि हमने देखा है कि प्रमोशन गतिविधियों के दौरान कंपनी के कॉर्पोरेट अफेयर्स में प्रमोटर बहुत महत्वपूर्ण होते हैं, इसलिए कंपनी के प्रबंधन पर उनका काफी नियंत्रण होता है तथा इस तरह वे जीवन भर कंपनी पर नियंत्रण बनाए रखते हैं और प्रमोटर ऐसे व्यक्ति भी होते हैं जो वास्तव में कॉर्पोरेट जीवन के साथ उतार चढ़ाव का अनुभव करते हैं\n",
      "------\n",
      "Source:  k ə n ʈʲ ɪ ɲ ʉː ʈ ə ɟ ɪ ʋ ʋ ɜː b ə l ɪ n s ʈ ɹ ə c ʃ ə n z  ɒ n h aw ʈ ə ɖ ɹ ɒː d̪ ə k a ʈ  a n ə ʋ ɒː ɖ d̪ ə tʃ aj l ɖ  h ʉː z ɖ ɹ ɒ ʋ ɪ ŋ  k l oː s ʎ iː ɾ ɪ z ɛ m b ə l z j ɒː z \n",
      "Predicted: अब, कैट और वॉड को कैसे हटाने के बारे में निर्देश देने में सक्षम रहें, जो कि क्रॉस लिंग एमेल्गेमल्स का उपयोग करते हैं\n",
      "Reference: यह मौखिक निर्देश देना जारी रखें कि बिल्ली का चित्र कैसे बनाना है और उस बच्चे को पुरस्कृत करें जिसकी ड्राइंग आपकी काल्पनिक तस्वीर के ज़्यादा क़रीब हो\n",
      "------\n",
      "Source:  a n ɖ  f aj n ə ʎ i  ʋ iː s p oː k ə b aw ʈ  d̪ a ʈ ɪ z  ɹ eː z ɪ ŋ m ə ɹ ɑː l ɒ ʋ  a n ɪ n ɖ ɪ ʋ ɪ dʒ ə l \n",
      "Predicted: और अंत में, हम इस बारे में बात करते हैं कि एक व्यक्ति का मनोबल बढ़ रहा है\n",
      "Reference: और अंत में हमने यह भी कहा कि इससे व्यक्ति का मनोबल विकसित होता है\n",
      "------\n",
      "Source: d̪ ə  p ɾ aj ʋ ə ʈ p l eː s m ɛ n  p ɹ oː s ɛ s  ɪ z k ə m p ʎ iː ʈ ʎ i  ɖ ɪ f ə ɾ ə n f ɹ ə m iː  p ə b ʎ ɪ k  ɪ s j ʉː  a ʋ s ɪ c ʊ ɾ ə ʈʲ i dʒ  \n",
      "Predicted: निजी प्लेसमेंट प्रक्रिया पूरी तरह से सार्वजनिक निर्गम से अलग होती है, जो कि सुरक्षा है\n",
      "Reference: निजी तौर पर शेयर आबंटन की प्रक्रिया प्रतिभूतियों के सार्वजनिक निर्गम से पूरी तरह से अलग है\n",
      "------\n",
      "Source:  d̪ eː ɑː  ɖ ə b ə l s p ɛ n ɖ ɪ ŋ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  m aj ɲ ɪ ŋ p ʉː l z  s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  ʋ a ʎ ɪ ɖ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  a n spn ʈ ɛ k n ɒ l ə dʒ i n ɛ ʈ ʋ ɜː k  t̪ ɹ ɛ ʈ s  ʋ ɪ l s iː ʋ ɒ n ɑː f ʈ ə ɾ d̪ iː ə d̪ ə ɾ \n",
      "Predicted: वे सुरक्षा खतरों को दंडित करने, सुरक्षा खतरों को प्रशासित करने, सुरक्षा खतरों, भेद्य सुरक्षा खतरों और दुर्भावनापूर्ण प्रौद्योगिकी, नेटवर्क खतरों को देखेंगे\n",
      "Reference: डबल स्पेंडिंग सिक्युरिटी थ्रेट, माइनिंग पूल सिक्युरिटी थ्रेट, वॉलट सिक्युरिटी थ्रेट, और ब्लॉकचैन प्रौद्योगिकी नेटवर्क खतरे\n",
      "------\n",
      "Source:  d̪ a ʈ  iː ʋ ə n  a  p ɜː s ə n  h ʉː s a ʈʲ ɪ s f aj z d̪ ə a k s ɛ s ɪ ŋ ɒ fʲ ɪ s ə ɾ \n",
      "Predicted: यह वह व्यक्ति है जो अधिकृत को एक्सेस कर रहा है\n",
      "Reference: वह भी ऐसा व्यक्ति, जो आकलन अधिकारी, दस्तावेजी साक्ष्य, पहुंच भुगतान के कारणों को पूरा करता है\n",
      "------\n",
      "\n",
      "\n",
      "\n",
      "--- Inference After Epoch 4.0 ---\n",
      "Source:  p ə ʈʲ ɪ n a s ʈ ɾ a ʈ ə dʒ i ɪ n p l eː s d̪ a ʈ ɲ iː ɖ z  ʈ ʉː bʲ iː  f ɒ l oː ɖ ɪ n d̪ iː ɪ ʋ ɛ n ʈ  ɒ ʋ  ɛ ɲ i ɒ ʋ d̪ ə  fʲ ʉː tʃ ə  t̪ ɹ ɛ ʈ s  ʈ ʉː d̪ ə n ɛ ʈ ʋ ɜː k  ɪ n  ə d̪ ə ʋ ɜː ɖ z  spn  m ɛ ʃ ə z  \n",
      "Predicted: एक रणनीति के रूप में, प्लेस में जिसे किसी भी प्रकार की भविष्य की खतरों के इवेंट में शामिल करने की आवश्यकता है\n",
      "Reference: भविष्य में किसी भी तरह के नेटवर्क के खतरों के लिए दूसरे शब्दों में, सक्रिय उपायों को लागू करने की आवश्यकता के लिए एक रणनीति बनाना\n",
      "------\n",
      "Source: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i s ɜː ʋ ɪ s ɪ z  ʃ ʊ ɖ ɪ n ʃ ʊ ə d̪ a ʈ j ʉː z ə z dʒ ə s ʈ p ɹ ə ʋ aj ɖ ɪ ŋ spn  b ɛ ɲ ɪ fʲ ɪ ʈ f ɹ ə m b ɛ ʈ ə ɾ  ɾ ɛ k ə m ə n ɖ eː ʃ ə n z  a n ɖ  s ɜː tʃ  ɾ ɪ z ə l ʈ s \n",
      "Predicted: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ता सिर्फ बेहतर संबंधों और सर्च परिणामों से बेहतर लाभ प्रदान करते हैं\n",
      "Reference: सिमेंटिक डिजिटल लाइब्रेरी सेवाओं को यह सुनिश्चित करना चाहिए कि उपयोगकर्ता केवल एनोटेशन प्रदान करें, बेहतर रिकमेंडेशंस ( और खोज परिणामों से लाभान्वित हों\n",
      "------\n",
      "Source:  d̪ ə p ɒ pʲ ʊ l a ɾ ɪ ʈʲ i  ɒ ʋ d̪ ə ʋ ɜː ɖ  ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  k a n bʲ iː ʈ ɾ eː s ʈ  ʈ ʉː d̪ ə ɖ ɪ dʒ ɪ ʈ ə l l aj b ɾ ə ɾ i  ɪ ɲ ɪ ʃ ə ʈʲ ɪ ʋ z  \n",
      "Predicted: शब्द डिजिटल लाइब्रेरी की लोकप्रियता को डिजिटल लाइब्रेरी के उपक्रमों के लिए देखा जा सकता है\n",
      "Reference: डिजिटल लाइब्रेरी शब्द की लोकप्रियता का पता डिजिटल लाइब्रेरी पहल से लगाया जा सकता है\n",
      "------\n",
      "Source: s ɪ m a n ʈʲ ɪ k ɖ ɪ dʒ ɪ ʈ ə l l aj b ɹ i z ʃ ʊ ɖ ɒː l s oː p ɹ ə ʋ aj ɖ ɾ ɛ k ə m ə n ɖ eː ʃ ə n z s ɜː ʋ ɪ s ɪ z  f ə ɪ ɡ z aː m p ə l  b eː s ʈ  ɑ n d̪ ə  k a n ʈ ɛ k s  a n ɖ ɾ ɪ s ɒː s ɪ z  spn  ɑː b eː s ʈ ɒ n k ə l a b ə ɾ eː ʈʲ ɪ ʋ fʲ ɪ l ʈ ə ɾ ɪ n  \n",
      "Predicted: सिमेंटिक डिजिटल लाइब्रेरी को सामग्री और संसाधनों के अनुकूलन के आधार पर, उदाहरण के लिए, सहयोगी फ़िल्टरिंग के आधार पर सिमेंटिक डिजिटल लाइब्रेरी को सिमेंटिक रिपॉजिटरी भी प्रदान किया जाना चाहिए\n",
      "Reference: सिमेंटिक डिजिटल लाइब्रेरी को भी रिकमेंडेशंस सेवाएं प्रदान करनी चाहिए, उदाहरण के लिए, संदर्भ और संसाधनों के आधार पर एनोटेशन कोलाबोरेटिव फ़िल्टरिंग पर आधारित हैं\n",
      "------\n",
      "Source:  m ʉː ʋ ɪ ŋ ɒ n  a s ʋ iː a ʋ s iː n d̪ a ʈ ɪ n d̪ ə p ɹ ə m oː ʃ ə n a k ʈʲ ɪ ʋ ɪ ʈʲ i z  d̪ a ʈ  d̪ iː  p ɹ ə m oː ʈ ə z ɑː ʋ ɛ ɾ i ɪ m p ɒː ʈ ə n ʈ  p ɜː s ə n z  ɪ n d̪ ə k ɒː p ə ɹ ə ʈ ə f ɛː z ɒ ʋ d̪ ə k ə m p ə ɲ i  s oː d̪ eː a ʋ ə ʋ ɛ ɹ i  b ɛ ʈ ə ɾ k ə n ʈ ɹ oː l oː ʋ ə d̪ ə m a ɲ ɪ dʒ m ɛ n ʈ ɒ ʋ d̪ ə k ə m p ə ɲ i  a n d̪ eː c iː p d̪ ɪ s k ə n ʈ ɾ oː l  t̪ ɹ ʉː aw  d̪ ə l aj f ɒ ʋ d̪ iː  k ə m p ə ɲ i  a n ɖ  d̪ iː p ɹ ə m oː ʈ ə z  aː  ɒː l s oː  d̪ iː p ɜː s ə n z  h ʉː  a k ʈ ʉ ə ʎ i s ɪ ŋ k  a n ɖ  s ʋ ɪ m  ʋ ɪ d̪ d̪ ə  k ɒː p ə ɾ ə ʈ  l aj f \n",
      "Predicted: आगे बढ़ते हुए, जैसा कि हमने देखा है कि कंपनी की योजनाओं में प्रमोटर बहुत महत्वपूर्ण हैं और कॉर्पोरेट मामलों में प्रमोटर भी महत्वपूर्ण हैं\n",
      "Reference: आगे बढ़ते हुए, जैसा कि हमने देखा है कि प्रमोशन गतिविधियों के दौरान कंपनी के कॉर्पोरेट अफेयर्स में प्रमोटर बहुत महत्वपूर्ण होते हैं, इसलिए कंपनी के प्रबंधन पर उनका काफी नियंत्रण होता है तथा इस तरह वे जीवन भर कंपनी पर नियंत्रण बनाए रखते हैं और प्रमोटर ऐसे व्यक्ति भी होते हैं जो वास्तव में कॉर्पोरेट जीवन के साथ उतार चढ़ाव का अनुभव करते हैं\n",
      "------\n",
      "Source:  k ə n ʈʲ ɪ ɲ ʉː ʈ ə ɟ ɪ ʋ ʋ ɜː b ə l ɪ n s ʈ ɹ ə c ʃ ə n z  ɒ n h aw ʈ ə ɖ ɹ ɒː d̪ ə k a ʈ  a n ə ʋ ɒː ɖ d̪ ə tʃ aj l ɖ  h ʉː z ɖ ɹ ɒ ʋ ɪ ŋ  k l oː s ʎ iː ɾ ɪ z ɛ m b ə l z j ɒː z \n",
      "Predicted: आइए आने वाले मॉड्यूल में इन विषयों पर विस्तार से बताने का प्रयास करते हैं\n",
      "Reference: यह मौखिक निर्देश देना जारी रखें कि बिल्ली का चित्र कैसे बनाना है और उस बच्चे को पुरस्कृत करें जिसकी ड्राइंग आपकी काल्पनिक तस्वीर के ज़्यादा क़रीब हो\n",
      "------\n",
      "Source:  a n ɖ  f aj n ə ʎ i  ʋ iː s p oː k ə b aw ʈ  d̪ a ʈ ɪ z  ɹ eː z ɪ ŋ m ə ɹ ɑː l ɒ ʋ  a n ɪ n ɖ ɪ ʋ ɪ dʒ ə l \n",
      "Predicted: और अंत में, हमने इस बारे में बताया कि यह एक व्यक्ति के मनोबल को बढ़ा रहा है\n",
      "Reference: और अंत में हमने यह भी कहा कि इससे व्यक्ति का मनोबल विकसित होता है\n",
      "------\n",
      "Source: d̪ ə  p ɾ aj ʋ ə ʈ p l eː s m ɛ n  p ɹ oː s ɛ s  ɪ z k ə m p ʎ iː ʈ ʎ i  ɖ ɪ f ə ɾ ə n f ɹ ə m iː  p ə b ʎ ɪ k  ɪ s j ʉː  a ʋ s ɪ c ʊ ɾ ə ʈʲ i dʒ  \n",
      "Predicted: निजी प्लेसमेंट प्रक्रिया प्रतिभूतियों के सार्वजनिक निर्गम से पूरी तरह से अलग होती है\n",
      "Reference: निजी तौर पर शेयर आबंटन की प्रक्रिया प्रतिभूतियों के सार्वजनिक निर्गम से पूरी तरह से अलग है\n",
      "------\n",
      "Source:  d̪ eː ɑː  ɖ ə b ə l s p ɛ n ɖ ɪ ŋ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  m aj ɲ ɪ ŋ p ʉː l z  s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  ʋ a ʎ ɪ ɖ s ɪ c ʊ ɾ ə ʈʲ i t̪ ɹ ɛ ʈ s  a n spn ʈ ɛ k n ɒ l ə dʒ i n ɛ ʈ ʋ ɜː k  t̪ ɹ ɛ ʈ s  ʋ ɪ l s iː ʋ ɒ n ɑː f ʈ ə ɾ d̪ iː ə d̪ ə ɾ \n",
      "Predicted: वे प्रतिभूति खतरे, ऋण, पॉल, सुरक्षा खतरे, भेद्यता खतरे और आईओटी तकनीक, नेटवर्क खतरे, हम एक के बाद एक देखेंगे\n",
      "Reference: डबल स्पेंडिंग सिक्युरिटी थ्रेट, माइनिंग पूल सिक्युरिटी थ्रेट, वॉलट सिक्युरिटी थ्रेट, और ब्लॉकचैन प्रौद्योगिकी नेटवर्क खतरे\n",
      "------\n",
      "Source:  d̪ a ʈ  iː ʋ ə n  a  p ɜː s ə n  h ʉː s a ʈʲ ɪ s f aj z d̪ ə a k s ɛ s ɪ ŋ ɒ fʲ ɪ s ə ɾ \n",
      "Predicted: यह वो व्यक्ति है जो कार्यालय से बाहर पहुँच प्राप्त करता है\n",
      "Reference: वह भी ऐसा व्यक्ति, जो आकलन अधिकारी, दस्तावेजी साक्ष्य, पहुंच भुगतान के कारणों को पूरा करता है\n",
      "------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7296865,
     "sourceId": 11630187,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7296924,
     "sourceId": 11630272,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
